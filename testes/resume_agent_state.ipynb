{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4bc909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregue a chave da API do arquivo .env\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97ad95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chave da OpenAI carregada com sucesso!\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccb3aa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "Você é um modelo especializado em análise de contexto de conversas.\n",
    "\n",
    "Entrada:\n",
    "- Você receberá um state contendo as últimas 6 mensagens trocadas entre o cliente e o assistente.\n",
    "- Sua tarefa é identificar a mensagem (ou trecho) mais relevante em relação à **pergunta mais recente do cliente**.\n",
    "\n",
    "Instruções:\n",
    "1. Leia todas as mensagens no state.\n",
    "2. Identifique qual é a **última mensagem do cliente**.\n",
    "3. Analise as mensagens anteriores e selecione **a(s) informação(ões) mais diretamente úteis** para responder à pergunta mais recente.\n",
    "4. Ignore repetições, ruídos e mensagens sem relação com a pergunta atual.\n",
    "5. Retorne **somente o texto relevante**, de forma concisa, sem comentários adicionais.\n",
    "\n",
    "Formato de saída:\n",
    "{\n",
    "  \"contexto_relevante\": \"<trecho selecionado>\"\n",
    "}\n",
    "\n",
    "State (exemplo de entrada):\n",
    "[\n",
    "  {\"role\": \"user\", \"content\": \"O que é BM25?\"},\n",
    "  {\"role\": \"assistant\", \"content\": \"É um método de ranqueamento baseado em frequência de termos.\"},\n",
    "  {\"role\": \"user\", \"content\": \"E se tiver erro de digitação?\"},\n",
    "  {\"role\": \"assistant\", \"content\": \"Você pode adaptar com fuzzy matching ou trigramas.\"},\n",
    "  {\"role\": \"user\", \"content\": \"E se eu usar 3 caracteres por palavra?\"},\n",
    "  {\"role\": \"assistant\", \"content\": \"Isso se aproxima de um modelo de n-gramas.\"}\n",
    "]\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4395066",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"\"\"\n",
    "Pergunta: Como funciona o algoritmo BM25?\n",
    "\n",
    "Contexto: Ontem eu estava revisando alguns papéis antigos sobre SEO e percebi que muitos métodos de ranqueamento ainda são confundidos com modelos de machine learning. Aliás, o café da empresa acabou e o fornecedor atrasou a entrega. Falando nisso, o BM25 não tem nada a ver com café, mas é curioso que ambos envolvem “ranking”, de certo modo.  \n",
    "\n",
    "Em termos gerais, eu também gosto de comparar diferentes técnicas de busca, como TF-IDF, PageRank e, claro, o BM25, que é uma evolução do TF-IDF usada para ranquear documentos com base na relevância para uma consulta. Mas antes de entrar nisso, vale lembrar que na semana passada o servidor caiu e perdemos alguns índices, o que atrapalhou os testes.\n",
    "\n",
    "Voltando ao ponto: o **BM25 calcula a relevância de um documento com base na frequência do termo e no tamanho do documento**, usando dois parâmetros principais, **k1** (controla a saturação da frequência) e **b** (ajusta a normalização pelo tamanho do documento). Esses fatores ajudam a equilibrar o peso de termos muito frequentes e textos muito longos.  \n",
    "\n",
    "Inclusive, estou pensando em comprar uma nova cadeira ergonômica, porque a atual range quando inclino para trás. Outra coisa: se você ainda estiver com dor nas costas, tente alongar antes do trabalho.  \n",
    "\n",
    "Alguns estudos mostram que o BM25 costuma superar o TF-IDF em consultas curtas, pois o modelo é mais robusto à variação de frequência de termos. Em implementações práticas, como no Elasticsearch e no Lucene, ele é o padrão de ranqueamento.  \n",
    "\n",
    "Mas enfim, o almoço de hoje vai ser salada com frango, e o clima está estranho. Se chover, talvez eu não vá à academia.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087f2f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cbf1fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"contexto_relevante\": \"O BM25 calcula a relevância de um documento com base na frequência do termo e no tamanho do documento, usando dois parâmetros principais, k1 (controla a saturação da frequência) e b (ajusta a normalização pelo tamanho do documento). Esses fatores ajudam a equilibrar o peso de termos muito frequentes e textos muito longos. Alguns estudos mostram que o BM25 costuma superar o TF-IDF em consultas curtas, pois o modelo é mais robusto à variação de frequência de termos. Em implementações práticas, como no Elasticsearch e no Lucene, ele é o padrão de ranqueamento.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e7ab70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c471a0ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1668bfa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
