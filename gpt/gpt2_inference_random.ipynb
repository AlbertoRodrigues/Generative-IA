{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72f768d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_model import GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4204617",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 20\n",
    "n_layers       = 3\n",
    "n_heads        = 2\n",
    "n_embd         = 64\n",
    "max_tokens     = 12\n",
    "model = GPT(context_length, n_layers, n_heads, n_embd, max_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90f36d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_list = [\"o\", \"gato\", \"pequeno\"]\n",
    "model.init_tokens(tokens_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec0e9d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nome: wte.weight\n",
      "Shape: torch.Size([529, 64])\n",
      "Valores: Parameter containing:\n",
      "tensor([[ 0.7309,  0.4598, -1.3751,  ..., -2.1733, -0.2641, -0.4269],\n",
      "        [-1.3943, -0.0812, -0.3729,  ...,  0.1766,  0.8436,  1.0324],\n",
      "        [ 1.1605, -0.3243, -1.9835,  ..., -1.8315,  1.4158,  1.3294],\n",
      "        ...,\n",
      "        [ 0.8745, -0.2627, -0.8971,  ..., -0.5181, -1.9935,  0.2168],\n",
      "        [ 0.4584,  0.3086, -1.7110,  ...,  0.1087, -0.5400,  0.0528],\n",
      "        [-0.3324, -0.3105,  0.5953,  ..., -1.6827, -0.0029, -0.6938]],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: wpe.weight\n",
      "Shape: torch.Size([20, 64])\n",
      "Valores: Parameter containing:\n",
      "tensor([[ 0.6887, -1.7480, -0.6799,  ..., -0.3177, -0.9825, -1.0995],\n",
      "        [-0.2929, -0.4735, -0.0916,  ..., -2.4674,  0.7803, -1.9828],\n",
      "        [ 0.7351, -1.0266,  0.7430,  ...,  0.5056,  0.6156, -0.3699],\n",
      "        ...,\n",
      "        [ 0.2238,  0.6501, -1.2638,  ...,  1.2841,  1.5182, -1.0718],\n",
      "        [-1.3431, -1.7264, -0.4165,  ..., -0.0059, -2.1963,  0.5626],\n",
      "        [ 0.3352,  0.1306,  0.9662,  ...,  0.4691,  0.7109,  0.2190]],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: qkv_proj.0.weight\n",
      "Shape: torch.Size([192, 64])\n",
      "Valores: Parameter containing:\n",
      "tensor([[ 0.0491, -0.0665,  0.0223,  ...,  0.0337, -0.0875, -0.0399],\n",
      "        [-0.0344,  0.0763,  0.0395,  ...,  0.0953,  0.0625,  0.0541],\n",
      "        [-0.0269,  0.0591, -0.1112,  ...,  0.0457,  0.0998,  0.0893],\n",
      "        ...,\n",
      "        [-0.0172, -0.0108,  0.0470,  ...,  0.1039, -0.1189, -0.0011],\n",
      "        [-0.0538,  0.0351,  0.0914,  ...,  0.0417, -0.0118, -0.0652],\n",
      "        [ 0.0326, -0.0732, -0.0974,  ...,  0.0079, -0.0954,  0.1180]],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: qkv_proj.0.bias\n",
      "Shape: torch.Size([192])\n",
      "Valores: Parameter containing:\n",
      "tensor([ 0.1241, -0.0009, -0.1221,  0.0691,  0.0184, -0.1199, -0.0226,  0.0396,\n",
      "         0.0391, -0.1164,  0.0287,  0.0706,  0.0857,  0.0230, -0.0622,  0.0056,\n",
      "        -0.0275,  0.0197,  0.1039,  0.1066,  0.1232, -0.0109, -0.0676,  0.0293,\n",
      "         0.0102, -0.0234, -0.0324, -0.1013,  0.1192,  0.0898, -0.1223, -0.0170,\n",
      "        -0.0817, -0.0401,  0.0433,  0.0659,  0.0756,  0.0130,  0.0202, -0.1212,\n",
      "        -0.0288, -0.1205,  0.0815, -0.0915,  0.0472,  0.0593,  0.0503, -0.0526,\n",
      "        -0.1152, -0.0097,  0.0191,  0.0102,  0.0822,  0.0395,  0.0123, -0.0732,\n",
      "        -0.0648, -0.0753,  0.0127,  0.1009, -0.0147, -0.0359, -0.0665,  0.0686,\n",
      "         0.0376,  0.1061, -0.0214,  0.0885,  0.0901,  0.0808,  0.0345, -0.0573,\n",
      "        -0.0679, -0.0365, -0.0388,  0.0854, -0.0207,  0.0928,  0.0281, -0.1122,\n",
      "         0.1024,  0.0304,  0.0096, -0.0216,  0.0145,  0.0461, -0.0761,  0.0007,\n",
      "        -0.0271, -0.1137,  0.0577, -0.0477, -0.1244,  0.0716,  0.0829,  0.0547,\n",
      "        -0.0906,  0.0043, -0.0962,  0.0171,  0.0226,  0.0239, -0.1014, -0.0489,\n",
      "         0.1064, -0.0019, -0.1068, -0.0364, -0.0880, -0.0298,  0.0004, -0.0503,\n",
      "         0.0037, -0.0202,  0.0470, -0.0191,  0.0429, -0.0743,  0.1173, -0.1059,\n",
      "         0.0403,  0.0711,  0.0561, -0.1138, -0.0106,  0.1141, -0.0763,  0.1031,\n",
      "        -0.0406,  0.1228, -0.0076, -0.0082,  0.0571, -0.0540, -0.0479,  0.1212,\n",
      "         0.0964, -0.1169,  0.0785, -0.1011,  0.1005, -0.0305, -0.0298,  0.0366,\n",
      "        -0.0942, -0.0363, -0.0917, -0.0036,  0.0805, -0.0689, -0.0980,  0.0224,\n",
      "         0.0083,  0.0962, -0.0343, -0.0323,  0.0981, -0.0252,  0.0476,  0.0668,\n",
      "         0.0088, -0.1248, -0.0921,  0.0959, -0.0559, -0.0299, -0.0279, -0.1036,\n",
      "        -0.1076,  0.0919,  0.0512,  0.0735,  0.0732,  0.0629, -0.1196, -0.0458,\n",
      "         0.0884, -0.0177,  0.0796,  0.1250, -0.0820,  0.0257,  0.0917, -0.0430,\n",
      "        -0.1068,  0.0409,  0.0760, -0.0774, -0.1090, -0.0724, -0.0880,  0.0524],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: qkv_proj.1.weight\n",
      "Shape: torch.Size([192, 64])\n",
      "Valores: Parameter containing:\n",
      "tensor([[-0.0428, -0.0355, -0.0218,  ..., -0.0752, -0.0965,  0.1166],\n",
      "        [-0.1213,  0.0332, -0.0306,  ..., -0.0788, -0.0006, -0.0270],\n",
      "        [-0.0727, -0.0079,  0.0051,  ..., -0.0949, -0.0222, -0.1188],\n",
      "        ...,\n",
      "        [ 0.0162, -0.1174, -0.1065,  ..., -0.1240, -0.0225,  0.0772],\n",
      "        [-0.0733, -0.0720,  0.1215,  ...,  0.0840,  0.1078, -0.0341],\n",
      "        [-0.0770, -0.0578,  0.1065,  ..., -0.0416, -0.0037, -0.1095]],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: qkv_proj.1.bias\n",
      "Shape: torch.Size([192])\n",
      "Valores: Parameter containing:\n",
      "tensor([ 0.0108,  0.0641, -0.0480,  0.0404,  0.0073,  0.0633,  0.0352, -0.0862,\n",
      "         0.0806, -0.1122,  0.0399, -0.0158, -0.0467, -0.0632,  0.1063, -0.0595,\n",
      "         0.0483, -0.0048,  0.0150,  0.0626,  0.0437, -0.0367, -0.0600, -0.0795,\n",
      "        -0.1239,  0.1017, -0.0515, -0.0950, -0.0415,  0.0494, -0.0587, -0.1085,\n",
      "         0.0851,  0.0247,  0.0298,  0.1159,  0.1233,  0.0566,  0.0442, -0.0463,\n",
      "        -0.0355,  0.0406,  0.0456,  0.0857, -0.0407, -0.0868, -0.1109, -0.0673,\n",
      "        -0.1112, -0.0100,  0.0098,  0.0581, -0.0447,  0.0286,  0.0884,  0.0588,\n",
      "         0.0571, -0.0457, -0.1180, -0.0708, -0.0235,  0.0726, -0.0632,  0.0484,\n",
      "         0.0101, -0.0257, -0.0884,  0.0859, -0.0739, -0.0516, -0.0618,  0.1249,\n",
      "        -0.0108,  0.0384,  0.0263,  0.0492,  0.0700,  0.1159, -0.0574,  0.0806,\n",
      "        -0.0765, -0.0065, -0.1033,  0.0823,  0.0371, -0.0168,  0.1070,  0.0943,\n",
      "        -0.0568,  0.0897, -0.1165, -0.1230, -0.0716,  0.0049,  0.0007, -0.0935,\n",
      "        -0.1207, -0.0079,  0.0586, -0.0780,  0.0927, -0.0986, -0.0352, -0.0433,\n",
      "        -0.0268,  0.0394,  0.1138,  0.1144,  0.0444, -0.0943, -0.0192, -0.0661,\n",
      "         0.0638,  0.0979,  0.1101,  0.0655,  0.1055, -0.0868, -0.0026,  0.0679,\n",
      "        -0.0949,  0.0409,  0.1130, -0.1182, -0.0110,  0.0542, -0.1056, -0.0692,\n",
      "        -0.0768, -0.0285, -0.0553, -0.1030, -0.1016, -0.0317, -0.0508, -0.1030,\n",
      "        -0.0154, -0.0779,  0.0083,  0.0478,  0.0211,  0.0947,  0.0487,  0.0980,\n",
      "         0.0526, -0.0776, -0.0072, -0.1063,  0.0503,  0.0163,  0.0144,  0.0808,\n",
      "         0.1199,  0.0402,  0.1043,  0.0501, -0.0351, -0.0945,  0.0018, -0.0521,\n",
      "         0.1069, -0.0992, -0.0688,  0.0726, -0.0706,  0.0512, -0.0338, -0.0965,\n",
      "         0.0583,  0.1019,  0.0341,  0.1055,  0.1030,  0.0136, -0.0935,  0.1174,\n",
      "         0.0745,  0.0597,  0.0708, -0.0301,  0.0994, -0.0086, -0.0099, -0.0974,\n",
      "         0.0094,  0.1232, -0.0715, -0.0087,  0.0841,  0.0711, -0.0279,  0.0062],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: qkv_proj.2.weight\n",
      "Shape: torch.Size([192, 64])\n",
      "Valores: Parameter containing:\n",
      "tensor([[-0.0409,  0.1239, -0.0678,  ...,  0.1138,  0.0390,  0.0690],\n",
      "        [-0.1127, -0.0623,  0.0945,  ...,  0.0803,  0.0868,  0.0163],\n",
      "        [-0.0589, -0.0019, -0.0537,  ...,  0.0378, -0.1030,  0.0790],\n",
      "        ...,\n",
      "        [-0.0903, -0.1019,  0.0670,  ..., -0.0627,  0.0283,  0.0789],\n",
      "        [-0.1157, -0.1154,  0.0899,  ..., -0.1246,  0.0556,  0.0011],\n",
      "        [-0.0866, -0.0203,  0.0634,  ...,  0.0726,  0.0010, -0.0212]],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: qkv_proj.2.bias\n",
      "Shape: torch.Size([192])\n",
      "Valores: Parameter containing:\n",
      "tensor([ 0.0709, -0.0059, -0.0866, -0.0750, -0.0211, -0.0619,  0.0307, -0.0109,\n",
      "         0.0974,  0.0810,  0.0422,  0.0336,  0.0631,  0.0726, -0.1155, -0.0010,\n",
      "         0.0175,  0.0626,  0.1033, -0.0519,  0.0640,  0.0386,  0.0906, -0.0528,\n",
      "         0.0686, -0.0610, -0.1104,  0.0824,  0.0286,  0.0885, -0.1026, -0.1067,\n",
      "         0.0681, -0.1037,  0.0259,  0.0518, -0.0680, -0.0782,  0.0429, -0.0432,\n",
      "         0.0181,  0.1249, -0.0060,  0.0870, -0.0334,  0.1229, -0.1134, -0.0633,\n",
      "         0.0637, -0.0446,  0.1123,  0.0696,  0.0703,  0.0021, -0.1050, -0.0759,\n",
      "        -0.0104, -0.0441,  0.0669, -0.0637, -0.0267,  0.0164, -0.0246, -0.0760,\n",
      "        -0.0416, -0.0259, -0.1170, -0.1226, -0.0301,  0.0097,  0.0621,  0.0825,\n",
      "        -0.0384, -0.0699, -0.0403, -0.0530, -0.0689,  0.1238, -0.0920, -0.0565,\n",
      "         0.0631,  0.1006, -0.0832,  0.0435,  0.0687, -0.0928, -0.0255, -0.0131,\n",
      "         0.1135,  0.0735,  0.0215, -0.0596,  0.0582,  0.1072,  0.0348, -0.0545,\n",
      "         0.0228,  0.0346,  0.0444,  0.0460, -0.0189,  0.0554,  0.0177, -0.0462,\n",
      "        -0.1074, -0.0850,  0.0145, -0.0147, -0.0355,  0.0762, -0.0407,  0.0714,\n",
      "         0.0205, -0.1009, -0.1148, -0.0704,  0.1189, -0.0493,  0.0396, -0.0092,\n",
      "        -0.0867, -0.1201,  0.0233,  0.0385, -0.0401, -0.0210, -0.0272, -0.1016,\n",
      "         0.0468,  0.0375, -0.0413, -0.0060,  0.0317,  0.1020, -0.1245, -0.0158,\n",
      "        -0.0455,  0.0795,  0.0278, -0.0357,  0.0568,  0.0577,  0.1085, -0.1038,\n",
      "        -0.0011,  0.0407,  0.0177, -0.0219, -0.1126, -0.1004,  0.1104,  0.0027,\n",
      "        -0.0843, -0.1112,  0.0146,  0.0650,  0.1238, -0.1216,  0.0637, -0.1151,\n",
      "         0.0531, -0.0539, -0.0673,  0.0380, -0.0339, -0.0835, -0.0246,  0.0886,\n",
      "        -0.0642,  0.0923,  0.0398, -0.0683, -0.0353,  0.0641, -0.1020, -0.0270,\n",
      "         0.0017, -0.0311, -0.0793, -0.0501,  0.0575, -0.1074, -0.0742, -0.0524,\n",
      "         0.0534,  0.1170,  0.0784, -0.1242,  0.0669, -0.0840,  0.1124, -0.1112],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: out_proj.0.weight\n",
      "Shape: torch.Size([64, 64])\n",
      "Valores: Parameter containing:\n",
      "tensor([[ 0.0608, -0.1003, -0.0383,  ..., -0.0439, -0.0359,  0.0250],\n",
      "        [-0.0841,  0.0640,  0.1079,  ...,  0.0094,  0.0026, -0.0938],\n",
      "        [-0.0478, -0.0580,  0.0383,  ...,  0.1199,  0.1211, -0.0030],\n",
      "        ...,\n",
      "        [ 0.0668,  0.0667, -0.0259,  ...,  0.0402,  0.0763, -0.1207],\n",
      "        [ 0.0917,  0.0244, -0.0612,  ..., -0.0389,  0.0277, -0.0865],\n",
      "        [-0.0979,  0.0554,  0.0860,  ..., -0.0633,  0.0246,  0.0043]],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: out_proj.0.bias\n",
      "Shape: torch.Size([64])\n",
      "Valores: Parameter containing:\n",
      "tensor([-0.0274, -0.0208, -0.0928,  0.0713,  0.0189,  0.1159, -0.0284,  0.0789,\n",
      "        -0.0526,  0.0585,  0.0002,  0.0237, -0.0751,  0.0078,  0.0641, -0.0386,\n",
      "         0.0385, -0.0506,  0.1090,  0.0595, -0.0483, -0.0061, -0.0750, -0.0480,\n",
      "        -0.0090,  0.0787,  0.0657, -0.1154,  0.0805,  0.0911,  0.0030,  0.0845,\n",
      "         0.0450, -0.0680,  0.1020, -0.0014, -0.0872, -0.1099,  0.0036, -0.0585,\n",
      "        -0.0977, -0.1083,  0.0556,  0.0953, -0.0182,  0.0213, -0.0074, -0.0239,\n",
      "         0.0419,  0.0172, -0.0910, -0.0829, -0.0858, -0.0930,  0.0358,  0.1047,\n",
      "        -0.1243, -0.0079,  0.0114, -0.1152, -0.1061, -0.1141,  0.0134,  0.0123],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: out_proj.1.weight\n",
      "Shape: torch.Size([64, 64])\n",
      "Valores: Parameter containing:\n",
      "tensor([[ 0.0750,  0.0694,  0.0247,  ..., -0.0730, -0.0373, -0.0332],\n",
      "        [-0.0273, -0.0334,  0.0190,  ...,  0.0318,  0.0151,  0.0874],\n",
      "        [-0.1148, -0.0778, -0.0238,  ..., -0.0086,  0.0282, -0.0875],\n",
      "        ...,\n",
      "        [ 0.0866,  0.1245,  0.0750,  ..., -0.1126,  0.0609, -0.0908],\n",
      "        [ 0.0187,  0.0633,  0.0866,  ..., -0.0608,  0.0589, -0.0093],\n",
      "        [ 0.0466, -0.0263, -0.1048,  ..., -0.0400, -0.0720, -0.0794]],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: out_proj.1.bias\n",
      "Shape: torch.Size([64])\n",
      "Valores: Parameter containing:\n",
      "tensor([-0.0448, -0.0755, -0.1144,  0.0337, -0.0715, -0.0885,  0.0307,  0.0064,\n",
      "         0.0337,  0.0191, -0.0578, -0.0132,  0.1240,  0.1034, -0.0722, -0.0567,\n",
      "         0.1043,  0.0679, -0.0669,  0.1244, -0.1170,  0.0976, -0.1012,  0.0906,\n",
      "         0.0247, -0.1231,  0.0905, -0.0459,  0.0717, -0.1237,  0.1215, -0.1124,\n",
      "        -0.0515, -0.1023,  0.0938, -0.1238,  0.0116, -0.0017, -0.0798,  0.0626,\n",
      "         0.0190,  0.0844,  0.0190, -0.0201,  0.0297, -0.0443, -0.0139, -0.1225,\n",
      "         0.1120,  0.0324, -0.0143, -0.0490, -0.1003, -0.1008,  0.0773, -0.0434,\n",
      "         0.0810, -0.1162,  0.1004, -0.0364, -0.0150,  0.0753, -0.0879,  0.0100],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: out_proj.2.weight\n",
      "Shape: torch.Size([64, 64])\n",
      "Valores: Parameter containing:\n",
      "tensor([[ 0.0524,  0.0531,  0.1236,  ..., -0.1041, -0.0947, -0.0811],\n",
      "        [-0.0347, -0.0535,  0.0300,  ..., -0.0263, -0.0512, -0.1006],\n",
      "        [-0.0133, -0.0701, -0.0639,  ...,  0.0293, -0.0668,  0.0688],\n",
      "        ...,\n",
      "        [ 0.0247, -0.0527, -0.0716,  ...,  0.1001,  0.1177,  0.0019],\n",
      "        [ 0.0402,  0.0385, -0.0917,  ...,  0.0817, -0.1013, -0.0258],\n",
      "        [ 0.0704,  0.0907, -0.0987,  ...,  0.0645, -0.0494,  0.0294]],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: out_proj.2.bias\n",
      "Shape: torch.Size([64])\n",
      "Valores: Parameter containing:\n",
      "tensor([ 0.1041,  0.0596,  0.0237, -0.0604, -0.0808,  0.1247,  0.1058, -0.1184,\n",
      "         0.1115, -0.0099, -0.0459,  0.0200, -0.0990, -0.0944, -0.0147, -0.0871,\n",
      "        -0.0577,  0.0479,  0.0893, -0.1007,  0.0431, -0.0186,  0.1012,  0.0770,\n",
      "        -0.0979,  0.0542,  0.1216,  0.0794, -0.0350, -0.0499, -0.0848, -0.0454,\n",
      "         0.0359,  0.1174,  0.0900,  0.1248, -0.0540,  0.0678, -0.1139, -0.0021,\n",
      "        -0.0932, -0.0638, -0.0328, -0.0375,  0.1036, -0.1003, -0.0086, -0.0019,\n",
      "         0.0205,  0.1156, -0.1045, -0.0533,  0.0438, -0.0492, -0.1234,  0.1096,\n",
      "        -0.0497,  0.0048,  0.0447,  0.0593, -0.0614,  0.0178,  0.0218,  0.0904],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: mlp.0.0.weight\n",
      "Shape: torch.Size([128, 64])\n",
      "Valores: Parameter containing:\n",
      "tensor([[ 0.1128,  0.0994, -0.0726,  ...,  0.0809, -0.0767, -0.1158],\n",
      "        [-0.0912,  0.0017,  0.0531,  ...,  0.1143,  0.0998,  0.1132],\n",
      "        [-0.0079, -0.0043, -0.0861,  ...,  0.0607, -0.0841, -0.0529],\n",
      "        ...,\n",
      "        [-0.1083, -0.0404,  0.0432,  ...,  0.0484,  0.0233,  0.1080],\n",
      "        [ 0.0776, -0.0121, -0.1115,  ..., -0.0137, -0.0382, -0.1199],\n",
      "        [-0.0932, -0.0085, -0.0959,  ..., -0.0160,  0.0144, -0.0936]],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: mlp.0.0.bias\n",
      "Shape: torch.Size([128])\n",
      "Valores: Parameter containing:\n",
      "tensor([ 0.0511,  0.0115,  0.0366, -0.0972, -0.0666,  0.1101,  0.1097, -0.0499,\n",
      "        -0.0992,  0.0664, -0.0148,  0.0809, -0.1127,  0.0638,  0.1204,  0.0042,\n",
      "        -0.0441,  0.1087, -0.0413, -0.0309, -0.0511,  0.0813,  0.1156,  0.0028,\n",
      "        -0.1055,  0.1068,  0.0382, -0.1147,  0.1240, -0.0175, -0.1207,  0.0341,\n",
      "        -0.0740,  0.0665,  0.0887,  0.1171,  0.0541,  0.0515, -0.1138, -0.0990,\n",
      "         0.0414, -0.0756, -0.0560,  0.1093, -0.0477,  0.0343, -0.0442,  0.0415,\n",
      "         0.0684,  0.0421,  0.0145,  0.0739,  0.0388, -0.0224,  0.0674, -0.1229,\n",
      "         0.0913, -0.0182,  0.0550,  0.0828, -0.0585,  0.0212, -0.0775,  0.1018,\n",
      "         0.0593,  0.0776,  0.0272, -0.0249,  0.0553,  0.0840, -0.0023, -0.1161,\n",
      "         0.0518, -0.0069,  0.0469,  0.0528, -0.0012,  0.0396, -0.0825,  0.1140,\n",
      "        -0.0237,  0.0030,  0.0834,  0.1106, -0.0814, -0.0453,  0.1064, -0.0162,\n",
      "         0.0128, -0.1165,  0.0350, -0.0327, -0.1097,  0.0975,  0.0562, -0.1000,\n",
      "        -0.0371, -0.0437,  0.1244,  0.0302, -0.0655,  0.1200,  0.1031, -0.0463,\n",
      "         0.0902,  0.1027, -0.0553,  0.0818,  0.0150,  0.0452, -0.1218, -0.0620,\n",
      "         0.0887,  0.0749,  0.0957,  0.0045, -0.0215, -0.0099,  0.0212, -0.1129,\n",
      "         0.1206, -0.1124,  0.0703, -0.0183,  0.0397, -0.1063, -0.0113,  0.0431],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: mlp.0.2.weight\n",
      "Shape: torch.Size([64, 128])\n",
      "Valores: Parameter containing:\n",
      "tensor([[-0.0267, -0.0289,  0.0459,  ..., -0.0483,  0.0478,  0.0461],\n",
      "        [-0.0734, -0.0256, -0.0239,  ...,  0.0574, -0.0587, -0.0665],\n",
      "        [-0.0583,  0.0561, -0.0191,  ...,  0.0391, -0.0318,  0.0003],\n",
      "        ...,\n",
      "        [-0.0149, -0.0704, -0.0137,  ...,  0.0729,  0.0762, -0.0685],\n",
      "        [-0.0726, -0.0687, -0.0232,  ..., -0.0018,  0.0815,  0.0869],\n",
      "        [ 0.0337, -0.0857, -0.0773,  ..., -0.0408, -0.0391,  0.0264]],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: mlp.0.2.bias\n",
      "Shape: torch.Size([64])\n",
      "Valores: Parameter containing:\n",
      "tensor([-0.0358, -0.0276,  0.0470,  0.0417, -0.0585, -0.0124,  0.0606, -0.0447,\n",
      "         0.0620,  0.0717,  0.0249,  0.0360, -0.0649, -0.0699, -0.0067,  0.0321,\n",
      "         0.0484,  0.0693,  0.0092, -0.0260,  0.0114, -0.0077, -0.0318, -0.0629,\n",
      "         0.0323, -0.0831, -0.0614,  0.0110, -0.0184, -0.0074, -0.0633, -0.0607,\n",
      "        -0.0770,  0.0483, -0.0005, -0.0071, -0.0691, -0.0335, -0.0510, -0.0883,\n",
      "         0.0014, -0.0339,  0.0625,  0.0535, -0.0736, -0.0162,  0.0226, -0.0807,\n",
      "         0.0396,  0.0816, -0.0766, -0.0871,  0.0091,  0.0830, -0.0280, -0.0336,\n",
      "        -0.0080, -0.0781, -0.0004, -0.0146, -0.0125, -0.0249, -0.0530,  0.0228],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: mlp.1.0.weight\n",
      "Shape: torch.Size([128, 64])\n",
      "Valores: Parameter containing:\n",
      "tensor([[-1.5734e-02, -1.6851e-02,  9.3864e-02,  ...,  8.1456e-02,\n",
      "          2.1750e-02,  1.1470e-01],\n",
      "        [ 1.1970e-01,  3.1829e-02,  7.0610e-02,  ...,  1.0869e-01,\n",
      "          1.1592e-01, -9.0541e-03],\n",
      "        [-1.1577e-01,  6.1479e-02, -1.2746e-02,  ...,  1.1788e-01,\n",
      "         -7.0479e-02, -1.8592e-02],\n",
      "        ...,\n",
      "        [-6.0350e-05,  8.0627e-02,  1.1215e-02,  ...,  8.1269e-03,\n",
      "         -5.1965e-02,  6.8225e-02],\n",
      "        [-1.1924e-02,  1.1007e-01,  4.9084e-02,  ..., -1.1313e-02,\n",
      "          4.8956e-03,  3.4562e-02],\n",
      "        [-1.1632e-01, -1.0173e-02, -8.0008e-02,  ..., -8.0092e-02,\n",
      "         -7.4221e-03,  1.1885e-01]], requires_grad=True)\n",
      "\n",
      "Nome: mlp.1.0.bias\n",
      "Shape: torch.Size([128])\n",
      "Valores: Parameter containing:\n",
      "tensor([ 0.0072,  0.0820, -0.1014, -0.0373,  0.1142,  0.0826,  0.0145,  0.0226,\n",
      "        -0.1232,  0.0470,  0.0122, -0.1097,  0.1190, -0.0550, -0.1124,  0.1027,\n",
      "        -0.1147,  0.0213, -0.0615, -0.0040, -0.0011, -0.0549,  0.0942,  0.0571,\n",
      "        -0.0902, -0.0570,  0.0836, -0.0343,  0.0985, -0.0111,  0.0193, -0.0976,\n",
      "        -0.1051, -0.0367, -0.0858, -0.0021, -0.1249,  0.1094, -0.0061, -0.0918,\n",
      "        -0.1127, -0.0784, -0.0048,  0.0858, -0.0912,  0.0671, -0.0885, -0.0381,\n",
      "        -0.0287,  0.0803, -0.0707,  0.0835,  0.0679,  0.0572, -0.0273, -0.0874,\n",
      "        -0.0552,  0.0004,  0.1210,  0.0098,  0.0208, -0.0090,  0.0850,  0.1027,\n",
      "        -0.0492, -0.1178, -0.0120, -0.0073,  0.0253,  0.0310,  0.0448, -0.0311,\n",
      "         0.0535, -0.1108,  0.0653,  0.1181, -0.0373, -0.0909,  0.1010, -0.0961,\n",
      "         0.1078,  0.0066,  0.0038,  0.1229, -0.0510, -0.0252, -0.1096,  0.0950,\n",
      "         0.0959,  0.0958, -0.1134,  0.0832, -0.0093, -0.0774, -0.0793,  0.0621,\n",
      "        -0.0472, -0.0441, -0.0922, -0.1182, -0.0113, -0.1105, -0.0846,  0.0319,\n",
      "         0.0415,  0.1213, -0.0878,  0.0025, -0.0730,  0.0083,  0.1243, -0.1072,\n",
      "         0.0004,  0.0327, -0.0134,  0.0771,  0.1199, -0.0367,  0.0535,  0.0171,\n",
      "         0.1211,  0.0869,  0.0887, -0.0382, -0.0964, -0.0364,  0.0415, -0.0543],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: mlp.1.2.weight\n",
      "Shape: torch.Size([64, 128])\n",
      "Valores: Parameter containing:\n",
      "tensor([[-0.0225, -0.0427,  0.0706,  ...,  0.0238,  0.0185,  0.0684],\n",
      "        [-0.0458, -0.0749,  0.0521,  ..., -0.0211, -0.0150,  0.0133],\n",
      "        [-0.0489,  0.0510,  0.0124,  ..., -0.0567, -0.0180,  0.0315],\n",
      "        ...,\n",
      "        [ 0.0749, -0.0053,  0.0406,  ...,  0.0059, -0.0578, -0.0205],\n",
      "        [ 0.0203, -0.0610,  0.0045,  ...,  0.0049,  0.0119,  0.0668],\n",
      "        [ 0.0586,  0.0592, -0.0699,  ..., -0.0789,  0.0801,  0.0417]],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: mlp.1.2.bias\n",
      "Shape: torch.Size([64])\n",
      "Valores: Parameter containing:\n",
      "tensor([-0.0774, -0.0745,  0.0546,  0.0265, -0.0155, -0.0246,  0.0174, -0.0636,\n",
      "         0.0371, -0.0394,  0.0846,  0.0143,  0.0732, -0.0790,  0.0678,  0.0397,\n",
      "        -0.0782,  0.0400,  0.0654, -0.0694,  0.0516,  0.0708, -0.0150, -0.0586,\n",
      "         0.0227,  0.0545,  0.0353, -0.0283, -0.0784, -0.0016,  0.0351, -0.0032,\n",
      "        -0.0705, -0.0165,  0.0773,  0.0293, -0.0220, -0.0015, -0.0583,  0.0212,\n",
      "         0.0351, -0.0753, -0.0801, -0.0504,  0.0031, -0.0446,  0.0825, -0.0501,\n",
      "        -0.0776,  0.0139,  0.0628,  0.0214, -0.0209, -0.0268,  0.0212, -0.0126,\n",
      "        -0.0574, -0.0729, -0.0773,  0.0070, -0.0063,  0.0088,  0.0648,  0.0787],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: mlp.2.0.weight\n",
      "Shape: torch.Size([128, 64])\n",
      "Valores: Parameter containing:\n",
      "tensor([[-0.0160,  0.0065,  0.1177,  ..., -0.0861, -0.0712,  0.0233],\n",
      "        [-0.0653, -0.0757, -0.0005,  ..., -0.1118, -0.0004,  0.0457],\n",
      "        [-0.0684, -0.0744, -0.0520,  ...,  0.0830,  0.0540, -0.1223],\n",
      "        ...,\n",
      "        [-0.0044,  0.0836, -0.0229,  ..., -0.0931, -0.1026,  0.0040],\n",
      "        [ 0.0691, -0.0907,  0.0137,  ..., -0.0512,  0.0303,  0.0459],\n",
      "        [ 0.0504,  0.0112,  0.0507,  ..., -0.0344, -0.0973,  0.0374]],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: mlp.2.0.bias\n",
      "Shape: torch.Size([128])\n",
      "Valores: Parameter containing:\n",
      "tensor([ 5.8003e-02, -7.8786e-02, -5.1661e-03,  4.7961e-02, -7.9301e-02,\n",
      "        -7.1283e-02,  9.5743e-03, -1.1892e-02,  4.6193e-02,  1.8594e-02,\n",
      "         6.1851e-03, -1.0973e-01,  3.4381e-02,  7.4528e-02,  1.0253e-01,\n",
      "        -8.9132e-02, -1.0845e-01, -5.7920e-02,  4.7471e-02,  7.1942e-02,\n",
      "         7.0406e-02,  2.6838e-02,  1.1967e-01, -9.7502e-02, -5.6617e-02,\n",
      "        -5.0337e-02,  1.0866e-01, -4.5282e-02, -1.0143e-02, -9.3642e-02,\n",
      "         1.2225e-01, -8.5015e-02,  8.7425e-02,  2.8458e-02,  4.0242e-02,\n",
      "         9.6160e-02,  1.2166e-01,  8.5907e-02,  1.1566e-01,  5.4091e-02,\n",
      "        -2.8833e-02,  1.2281e-01, -1.1758e-01,  1.1384e-01,  4.9689e-02,\n",
      "        -7.0496e-02,  6.5989e-02, -9.2180e-02, -9.9632e-02, -6.4797e-02,\n",
      "        -2.8301e-02, -5.1038e-03,  3.6002e-02,  4.5897e-02, -5.7338e-02,\n",
      "        -9.8787e-02,  1.2124e-01, -6.0245e-05,  3.0041e-05, -1.7448e-02,\n",
      "        -8.8561e-02, -1.7639e-02,  1.2481e-02, -3.0801e-02, -2.5366e-02,\n",
      "        -1.2370e-01, -1.1234e-01,  1.1409e-02, -1.1141e-01, -1.0719e-01,\n",
      "        -7.4607e-02, -9.0345e-02,  7.7910e-02,  9.7034e-02, -3.7419e-02,\n",
      "        -1.0194e-01,  3.3931e-02,  1.0075e-01,  9.3126e-03,  1.2076e-01,\n",
      "         1.0951e-01,  6.7240e-02, -1.1815e-01, -1.0751e-01,  7.9163e-02,\n",
      "        -7.9323e-03, -9.0467e-02,  3.5787e-02, -1.0038e-01, -8.4770e-03,\n",
      "         7.7035e-02, -2.4897e-02,  7.2827e-02,  2.3039e-03,  8.5414e-02,\n",
      "        -3.4565e-02, -1.5998e-02, -7.6341e-03, -4.3979e-02,  7.2591e-02,\n",
      "        -1.2222e-01,  4.3804e-02, -2.1874e-03, -8.0535e-02, -8.0047e-03,\n",
      "        -1.1087e-01, -3.7250e-02, -7.5034e-03, -5.2671e-02,  1.6742e-02,\n",
      "        -9.3212e-02,  2.2423e-02,  1.2483e-01, -2.5033e-02,  3.1836e-02,\n",
      "         3.2061e-02,  1.1422e-01, -1.0503e-01, -1.0853e-01, -1.2158e-01,\n",
      "        -4.1995e-03,  6.3961e-02, -8.5148e-03,  6.7969e-03, -1.0319e-02,\n",
      "         5.6092e-02, -6.5892e-02, -8.9555e-02], requires_grad=True)\n",
      "\n",
      "Nome: mlp.2.2.weight\n",
      "Shape: torch.Size([64, 128])\n",
      "Valores: Parameter containing:\n",
      "tensor([[-0.0754, -0.0109, -0.0525,  ..., -0.0059,  0.0501, -0.0403],\n",
      "        [ 0.0562, -0.0704, -0.0691,  ..., -0.0846, -0.0682, -0.0573],\n",
      "        [ 0.0423,  0.0846,  0.0353,  ...,  0.0620,  0.0336, -0.0455],\n",
      "        ...,\n",
      "        [-0.0009,  0.0197, -0.0049,  ..., -0.0275, -0.0841,  0.0291],\n",
      "        [-0.0703, -0.0725,  0.0551,  ...,  0.0295,  0.0505,  0.0867],\n",
      "        [ 0.0695, -0.0234, -0.0510,  ..., -0.0408, -0.0226, -0.0589]],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: mlp.2.2.bias\n",
      "Shape: torch.Size([64])\n",
      "Valores: Parameter containing:\n",
      "tensor([-8.2336e-02, -6.3172e-02, -1.1250e-02,  5.0990e-02,  4.0248e-02,\n",
      "        -7.3067e-03, -8.5212e-02, -5.1417e-02,  6.1893e-02, -6.8868e-02,\n",
      "         1.0176e-02,  5.2304e-02, -3.0738e-02,  3.8669e-05,  3.0650e-02,\n",
      "        -1.0572e-02,  3.0364e-02,  4.5308e-02,  7.3559e-02, -2.4732e-03,\n",
      "         1.7572e-02, -6.5327e-02, -5.7231e-02,  2.0311e-02,  2.7832e-02,\n",
      "        -2.8398e-02, -4.4832e-02,  5.8319e-02, -8.1299e-02, -1.4882e-02,\n",
      "         7.2059e-02,  6.5752e-02,  8.5945e-02,  8.1768e-02, -2.1961e-02,\n",
      "        -9.3842e-04, -6.9071e-02, -3.2869e-02, -5.2238e-02,  5.2247e-02,\n",
      "         8.2387e-02, -5.4563e-02,  6.3309e-02, -8.4853e-02, -2.2032e-02,\n",
      "         8.3636e-02,  7.4858e-02,  8.6233e-02, -3.9945e-02,  2.7321e-02,\n",
      "         3.3994e-02, -5.6235e-02, -1.5532e-03,  7.4313e-02,  6.2949e-02,\n",
      "        -6.6586e-03,  3.5337e-02, -3.5932e-02,  3.5868e-02,  6.1648e-03,\n",
      "         2.5565e-02,  7.9689e-02,  3.3850e-02,  2.3939e-02],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: ln.weight\n",
      "Shape: torch.Size([64])\n",
      "Valores: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "\n",
      "Nome: ln.bias\n",
      "Shape: torch.Size([64])\n",
      "Valores: Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "Nome: lm_head.weight\n",
      "Shape: torch.Size([529, 64])\n",
      "Valores: Parameter containing:\n",
      "tensor([[ 0.0152,  0.0511,  0.0539,  ...,  0.0935, -0.0500, -0.0785],\n",
      "        [ 0.0362, -0.0377, -0.0500,  ..., -0.0567,  0.1097,  0.0453],\n",
      "        [-0.0088,  0.0684,  0.1169,  ..., -0.0331, -0.1014, -0.1062],\n",
      "        ...,\n",
      "        [ 0.0492,  0.0597, -0.0053,  ...,  0.0076, -0.1023, -0.0252],\n",
      "        [-0.0036,  0.0277,  0.0646,  ..., -0.0949, -0.0507,  0.0119],\n",
      "        [ 0.0739,  0.0221,  0.1099,  ...,  0.0584,  0.1040, -0.0473]],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: lm_head.bias\n",
      "Shape: torch.Size([529])\n",
      "Valores: Parameter containing:\n",
      "tensor([-0.1249, -0.0412,  0.0710, -0.0159,  0.0838, -0.0823,  0.0790,  0.0313,\n",
      "         0.0560,  0.1189,  0.0079,  0.0619,  0.0020,  0.0700,  0.0840,  0.0987,\n",
      "        -0.0706,  0.0182, -0.0047, -0.0199,  0.0080, -0.0113,  0.0608,  0.0957,\n",
      "         0.0101, -0.0940,  0.1088, -0.0439, -0.0644,  0.0442,  0.0611, -0.0250,\n",
      "         0.0984,  0.1140,  0.0652, -0.0253,  0.1099, -0.0210,  0.0364, -0.0682,\n",
      "        -0.1130,  0.0411,  0.0922,  0.0272, -0.0932,  0.0591, -0.0846, -0.0137,\n",
      "        -0.0635,  0.0099,  0.0202,  0.0105,  0.0279, -0.0161,  0.0285, -0.0477,\n",
      "         0.1082, -0.0044, -0.0428,  0.0204, -0.0956, -0.0451, -0.0270, -0.1029,\n",
      "        -0.0860, -0.0519,  0.0654,  0.0911,  0.0107, -0.1157,  0.0843,  0.0848,\n",
      "         0.0387, -0.0400, -0.0268, -0.0006, -0.0150, -0.1236, -0.0043,  0.0457,\n",
      "        -0.0011, -0.0329, -0.0211, -0.0204,  0.0146,  0.0020,  0.1209, -0.0536,\n",
      "         0.1066, -0.0641, -0.0312, -0.0064,  0.0079, -0.0323,  0.0968, -0.1154,\n",
      "        -0.1186,  0.0475,  0.0486,  0.0285,  0.0129,  0.0317, -0.0778,  0.0818,\n",
      "         0.0074,  0.0098, -0.0911, -0.0982,  0.0124,  0.0838, -0.1115,  0.0899,\n",
      "         0.0242,  0.0446, -0.1100,  0.0729, -0.1227, -0.0065,  0.0346,  0.0576,\n",
      "         0.0786,  0.1004,  0.0170, -0.0135,  0.0732,  0.0561,  0.0131,  0.0580,\n",
      "         0.0438, -0.0728, -0.0661,  0.1126,  0.0824, -0.0386,  0.1135, -0.0273,\n",
      "         0.0169, -0.1029, -0.0098, -0.0453, -0.1184, -0.1075,  0.0981, -0.0552,\n",
      "         0.1173,  0.0118, -0.0472,  0.1123,  0.0235,  0.0091, -0.0067, -0.0486,\n",
      "        -0.0539, -0.0946, -0.0353,  0.1172,  0.0637, -0.0721,  0.0308, -0.0757,\n",
      "        -0.1203,  0.0175, -0.0535, -0.0853, -0.0046, -0.0910, -0.0668, -0.0711,\n",
      "         0.0751,  0.0941, -0.0430,  0.0942, -0.0225,  0.0127, -0.0132,  0.0240,\n",
      "        -0.0211, -0.0237, -0.0342, -0.0725, -0.0179,  0.1219, -0.0879, -0.0431,\n",
      "        -0.0612,  0.0565, -0.0196, -0.0170, -0.1246,  0.1014,  0.1049,  0.0182,\n",
      "        -0.1240,  0.0528, -0.0141,  0.0040,  0.0684, -0.0055, -0.0806, -0.0983,\n",
      "         0.0120,  0.0275,  0.0197,  0.0624,  0.0272,  0.0790, -0.0509,  0.1218,\n",
      "        -0.0795, -0.0169,  0.1046,  0.0321,  0.0800, -0.0785, -0.0815,  0.0415,\n",
      "         0.0955, -0.0099, -0.0866,  0.0695, -0.0805, -0.0054, -0.0272, -0.0487,\n",
      "        -0.0067,  0.0681,  0.1190, -0.1161,  0.0137, -0.0910,  0.0096, -0.0591,\n",
      "         0.1001,  0.0663, -0.0704, -0.0191,  0.0364,  0.0207,  0.0821,  0.0874,\n",
      "        -0.0826,  0.0793,  0.1108, -0.0335, -0.0142,  0.1018, -0.0218,  0.1083,\n",
      "        -0.0724,  0.0275, -0.1097, -0.0626, -0.0912, -0.0799,  0.0964, -0.0507,\n",
      "        -0.1000,  0.0054, -0.0862,  0.0825, -0.0130,  0.1133,  0.0447, -0.0228,\n",
      "        -0.1207,  0.0574,  0.0102,  0.0792,  0.0294,  0.0486, -0.0652,  0.1008,\n",
      "         0.0978, -0.0375, -0.0325,  0.0132, -0.0814, -0.0794,  0.0333, -0.0644,\n",
      "         0.1232,  0.0482, -0.0801, -0.1143,  0.1156,  0.0558,  0.0482, -0.0959,\n",
      "         0.0070, -0.0332,  0.0872,  0.0371, -0.0392,  0.0199,  0.1039, -0.1084,\n",
      "         0.0088,  0.0428, -0.0582, -0.1194,  0.0600,  0.0060, -0.0792, -0.1130,\n",
      "        -0.0009, -0.0633,  0.0625, -0.1108,  0.0210,  0.1173, -0.1220,  0.0261,\n",
      "         0.0647,  0.0152, -0.0013, -0.0192,  0.0309, -0.1074, -0.1213, -0.0384,\n",
      "        -0.0336, -0.0758, -0.0280,  0.0887,  0.0536,  0.1125, -0.1037, -0.1110,\n",
      "        -0.0495, -0.0410,  0.0824, -0.0501,  0.1102,  0.0051, -0.0874,  0.1021,\n",
      "         0.0122,  0.1177, -0.0842,  0.0097, -0.0614,  0.0232, -0.0996, -0.0157,\n",
      "        -0.0555, -0.0664, -0.0940,  0.0893,  0.0657,  0.0214,  0.0913, -0.0568,\n",
      "        -0.0891,  0.0689, -0.0103,  0.0125,  0.0271,  0.0301, -0.1113,  0.0897,\n",
      "        -0.1152, -0.1186,  0.0059,  0.0783,  0.0313,  0.1157, -0.0201, -0.0190,\n",
      "         0.0805,  0.1103, -0.0991,  0.0991, -0.0762,  0.1124, -0.1193,  0.0884,\n",
      "         0.0149, -0.0403,  0.0288,  0.0443, -0.0709, -0.0352,  0.0870,  0.0419,\n",
      "        -0.0517, -0.0520,  0.0207, -0.0643, -0.0447,  0.1236,  0.0067, -0.0619,\n",
      "         0.0103,  0.0969,  0.0807, -0.1106,  0.0695,  0.1236, -0.0303, -0.1225,\n",
      "         0.0402, -0.0423,  0.0222,  0.0691,  0.0842,  0.0903, -0.0482, -0.1209,\n",
      "        -0.0340,  0.0062, -0.0912, -0.0798,  0.0564,  0.0991, -0.1047, -0.1186,\n",
      "        -0.1085, -0.0202, -0.0110,  0.0750, -0.0800, -0.1106, -0.0467, -0.0293,\n",
      "        -0.0159,  0.0931,  0.0420,  0.0669, -0.0247,  0.0780, -0.0756,  0.0479,\n",
      "         0.0694, -0.0171, -0.0719, -0.0951, -0.0785,  0.0256, -0.0109,  0.0141,\n",
      "        -0.0196, -0.0644,  0.0520,  0.0156,  0.0867, -0.0567,  0.0774,  0.1146,\n",
      "        -0.0836,  0.0281,  0.1211,  0.0372, -0.0332,  0.0901, -0.0113,  0.1139,\n",
      "        -0.1003,  0.0551, -0.1071,  0.0822, -0.0307,  0.0476,  0.0374,  0.0701,\n",
      "         0.0734,  0.0583, -0.1150,  0.0014, -0.1015, -0.1210, -0.0496, -0.0702,\n",
      "        -0.1008,  0.0776, -0.0743,  0.0410,  0.0238,  0.0815, -0.0815,  0.1148,\n",
      "        -0.1115, -0.0661,  0.0311, -0.0739, -0.0812,  0.0953,  0.0848,  0.0820,\n",
      "        -0.0812,  0.0325,  0.0927, -0.0375,  0.1030, -0.0549, -0.0473, -0.0097,\n",
      "        -0.0198, -0.0015,  0.0712,  0.0007, -0.0862, -0.0435, -0.0981, -0.1232,\n",
      "        -0.0969, -0.0532, -0.0566,  0.0022,  0.0899, -0.0591,  0.0127, -0.0466,\n",
      "        -0.1237,  0.0233, -0.0792,  0.0161,  0.0822,  0.0603, -0.0245,  0.1064,\n",
      "         0.1142, -0.0897, -0.1190,  0.1093, -0.1108, -0.0883, -0.0083,  0.1175,\n",
      "         0.1129], requires_grad=True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"Nome: {name}\")\n",
    "    print(f\"Shape: {param.shape}\")\n",
    "    print(f\"Valores: {param}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "539ba1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT(\n",
      "  (wte): Embedding(529, 64)\n",
      "  (wpe): Embedding(20, 64)\n",
      "  (qkv_proj): ModuleList(\n",
      "    (0-2): 3 x Linear(in_features=64, out_features=192, bias=True)\n",
      "  )\n",
      "  (out_proj): ModuleList(\n",
      "    (0-2): 3 x Linear(in_features=64, out_features=64, bias=True)\n",
      "  )\n",
      "  (mlp): ModuleList(\n",
      "    (0-2): 3 x Sequential(\n",
      "      (0): Linear(in_features=64, out_features=128, bias=True)\n",
      "      (1): GELU(approximate='tanh')\n",
      "      (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "  (lm_head): Linear(in_features=64, out_features=529, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "344390bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total treinável: 169,169\n"
     ]
    }
   ],
   "source": [
    "total = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total treinável: {total:,d}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49746aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wte.weight                                   33,856\n",
      "wpe.weight                                    1,280\n",
      "qkv_proj.0.weight                            12,288\n",
      "qkv_proj.0.bias                                 192\n",
      "qkv_proj.1.weight                            12,288\n",
      "qkv_proj.1.bias                                 192\n",
      "qkv_proj.2.weight                            12,288\n",
      "qkv_proj.2.bias                                 192\n",
      "out_proj.0.weight                             4,096\n",
      "out_proj.0.bias                                  64\n",
      "out_proj.1.weight                             4,096\n",
      "out_proj.1.bias                                  64\n",
      "out_proj.2.weight                             4,096\n",
      "out_proj.2.bias                                  64\n",
      "mlp.0.0.weight                                8,192\n",
      "mlp.0.0.bias                                    128\n",
      "mlp.0.2.weight                                8,192\n",
      "mlp.0.2.bias                                     64\n",
      "mlp.1.0.weight                                8,192\n",
      "mlp.1.0.bias                                    128\n",
      "mlp.1.2.weight                                8,192\n",
      "mlp.1.2.bias                                     64\n",
      "mlp.2.0.weight                                8,192\n",
      "mlp.2.0.bias                                    128\n",
      "mlp.2.2.weight                                8,192\n",
      "mlp.2.2.bias                                     64\n",
      "lm_head.weight                               33,856\n",
      "lm_head.bias                                    529\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"{name:<40} {param.numel():>10,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45d1f33c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bem'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_next_token()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5d72df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passo 1: o gato pequeno\n",
      "Passo 2: o gato pequeno seis\n",
      "Passo 3: o gato pequeno seis terrível\n",
      "Passo 4: o gato pequeno seis terrível existir\n",
      "Passo 5: o gato pequeno seis terrível existir lei\n",
      "Passo 6: o gato pequeno seis terrível existir lei terrível\n",
      "Passo 7: o gato pequeno seis terrível existir lei terrível viagem\n",
      "Passo 8: o gato pequeno seis terrível existir lei terrível viagem doce\n",
      "Passo 9: o gato pequeno seis terrível existir lei terrível viagem doce embora\n",
      "Passo 10: o gato pequeno seis terrível existir lei terrível viagem doce embora rápido\n",
      "Passo 11: o gato pequeno seis terrível existir lei terrível viagem doce embora rápido algo\n",
      "Passo 12: o gato pequeno seis terrível existir lei terrível viagem doce embora rápido algo noite\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['o',\n",
       " 'gato',\n",
       " 'pequeno',\n",
       " 'seis',\n",
       " 'terrível',\n",
       " 'existir',\n",
       " 'lei',\n",
       " 'terrível',\n",
       " 'viagem',\n",
       " 'doce',\n",
       " 'embora',\n",
       " 'rápido',\n",
       " 'algo',\n",
       " 'noite',\n",
       " 'montanha']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_all_sentence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50974d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
