{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3223898f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from dataclasses import dataclass\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f68cb0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x:\n",
      "tensor([[1., 2., 3., 4.],\n",
      "        [5., 6., 7., 8.]])\n"
     ]
    }
   ],
   "source": [
    "# Configurações\n",
    "T = 2\n",
    "C = 4\n",
    "n_heads = 2\n",
    "head_dim = C // n_heads\n",
    "\n",
    "# Entrada: 2 tokens com embedding 4\n",
    "x = torch.tensor([\n",
    "    [1.0, 2.0, 3.0, 4.0],  # Token 0\n",
    "    [5.0, 6.0, 7.0, 8.0]   # Token 1\n",
    "])  # (T=2, C=4)\n",
    "\n",
    "print(\"Input x:\")\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff0432d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação manual de qkv_proj\n",
    "# Vamos criar uma camada Linear manual que apenas multiplica por 0.1, 0.2, 0.3\n",
    "qkv_proj_weight = torch.tensor([\n",
    "    [0.1, 0.2, 0.3, 0.4],   # Para q0\n",
    "    [0.5, 0.6, 0.7, 0.8],   # Para q1\n",
    "    [0.9, 1.0, 1.1, 1.2],   # Para q2\n",
    "    [1.3, 1.4, 1.5, 1.6],   # Para q3\n",
    "\n",
    "    [0.1, 0.2, 0.3, 0.4],   # Para k0\n",
    "    [0.5, 0.6, 0.7, 0.8],   # Para k1\n",
    "    [0.9, 1.0, 1.1, 1.2],   # Para k2\n",
    "    [1.3, 1.4, 1.5, 1.6],   # Para k3\n",
    "\n",
    "    [0.1, 0.2, 0.3, 0.4],   # Para v0\n",
    "    [0.5, 0.6, 0.7, 0.8],   # Para v1\n",
    "    [0.9, 1.0, 1.1, 1.2],   # Para v2\n",
    "    [1.3, 1.4, 1.5, 1.6]    # Para v3\n",
    "], dtype=torch.float32)  # shape: (3C=12, C=4)\n",
    "\n",
    "qkv_proj_bias = torch.zeros(12)  # Sem bias para simplificar\n",
    "\n",
    "# Para out_proj\n",
    "out_proj_weight = torch.eye(C)  # Identidade (não muda nada)\n",
    "out_proj_bias = torch.zeros(C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73cd51b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "qkv:\n",
      "tensor([[ 3.0000,  7.0000, 11.0000, 15.0000,  3.0000,  7.0000, 11.0000, 15.0000,\n",
      "          3.0000,  7.0000, 11.0000, 15.0000],\n",
      "        [ 7.0000, 17.4000, 27.8000, 38.2000,  7.0000, 17.4000, 27.8000, 38.2000,\n",
      "          7.0000, 17.4000, 27.8000, 38.2000]])\n",
      "\n",
      "q:\n",
      "tensor([[ 3.0000,  7.0000, 11.0000, 15.0000],\n",
      "        [ 7.0000, 17.4000, 27.8000, 38.2000]])\n",
      "\n",
      "k:\n",
      "tensor([[ 3.0000,  7.0000, 11.0000, 15.0000],\n",
      "        [ 7.0000, 17.4000, 27.8000, 38.2000]])\n",
      "\n",
      "v:\n",
      "tensor([[ 3.0000,  7.0000, 11.0000, 15.0000],\n",
      "        [ 7.0000, 17.4000, 27.8000, 38.2000]])\n"
     ]
    }
   ],
   "source": [
    "# Simulando a projeção QKV\n",
    "qkv = x @ qkv_proj_weight.t() + qkv_proj_bias  # (T, 12)\n",
    "\n",
    "print(\"\\nqkv:\")\n",
    "print(qkv)\n",
    "\n",
    "# Separando q, k, v\n",
    "q, k, v = qkv.chunk(3, dim=1)  # Cada um (T, C)\n",
    "print(\"\\nq:\")\n",
    "print(q)\n",
    "print(\"\\nk:\")\n",
    "print(k)\n",
    "print(\"\\nv:\")\n",
    "print(v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1da67eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "att = (q @ k.transpose(-2, -1)) / math.sqrt(head_dim)\n",
    "# (n_heads, T, T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d22d23b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.0000,  7.0000],\n",
       "        [ 7.0000, 17.4000],\n",
       "        [11.0000, 27.8000],\n",
       "        [15.0000, 38.2000]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.transpose(-2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d39f2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 285.6711,  722.3803],\n",
      "        [ 722.3803, 1827.0510]])\n"
     ]
    }
   ],
   "source": [
    "print(att)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15ff4f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1., 0.],\n",
      "          [1., 1.]]]])\n",
      "\n",
      "Attention Scores (depois da máscara):\n",
      "tensor([[[[ 285.6711,      -inf],\n",
      "          [ 722.3803, 1827.0510]]]])\n"
     ]
    }
   ],
   "source": [
    "# Criar máscara causal\n",
    "mask = torch.tril(torch.ones(T, T)).view(1, 1, T, T)  # (1,1,T,T)\n",
    "print(mask)\n",
    "\n",
    "# Aplicar\n",
    "att = att.masked_fill(mask[:, :, :T, :T] == 0, float('-inf'))\n",
    "\n",
    "print(\"\\nAttention Scores (depois da máscara):\")\n",
    "print(att)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c25046e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Attention Scores (depois do Softmax):\n",
      "tensor([[[[1., 0.],\n",
      "          [0., 1.]]]])\n"
     ]
    }
   ],
   "source": [
    "att = torch.softmax(att, dim=-1)\n",
    "\n",
    "print(\"\\nAttention Scores (depois do Softmax):\")\n",
    "print(att)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8758ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output das heads (y):\n",
      "tensor([[[[ 3.0000,  7.0000, 11.0000, 15.0000],\n",
      "          [ 7.0000, 17.4000, 27.8000, 38.2000]]]])\n"
     ]
    }
   ],
   "source": [
    "y = att @ v  # (n_heads, T, head_dim)\n",
    "\n",
    "print(\"\\nOutput das heads (y):\")\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a8800a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output concatenado (após juntar heads):\n",
      "tensor([[ 3.0000,  7.0000, 11.0000, 15.0000],\n",
      "        [ 7.0000, 17.4000, 27.8000, 38.2000]])\n"
     ]
    }
   ],
   "source": [
    "y = y.transpose(0, 1).contiguous().view(T, C)  # (T, C)\n",
    "\n",
    "print(\"\\nOutput concatenado (após juntar heads):\")\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3827a56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saída final depois da projeção:\n",
      "tensor([[ 3.0000,  7.0000, 11.0000, 15.0000],\n",
      "        [ 7.0000, 17.4000, 27.8000, 38.2000]])\n"
     ]
    }
   ],
   "source": [
    "# Aplicar projeção final (vamos usar identidade)\n",
    "out_proj_weight = torch.eye(C)\n",
    "out_proj_bias = torch.zeros(C)\n",
    "\n",
    "y = y @ out_proj_weight.t() + out_proj_bias\n",
    "\n",
    "print(\"\\nSaída final depois da projeção:\")\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0cd673",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
