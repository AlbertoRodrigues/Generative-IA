{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72f768d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_model import GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4204617",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 20\n",
    "n_layers       = 3\n",
    "n_heads        = 2\n",
    "n_embd         = 64\n",
    "max_tokens     = 12\n",
    "model = GPT(context_length, n_layers, n_heads, n_embd, max_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90f36d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_list = [\"o\", \"gato\", \"pequeno\"]\n",
    "model.init_tokens(tokens_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec0e9d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nome: wte.weight\n",
      "Shape: torch.Size([529, 64])\n",
      "Valores: Parameter containing:\n",
      "tensor([[-0.5893, -0.4524,  1.1952,  ...,  0.3742,  1.4256,  0.0846],\n",
      "        [ 1.4145, -0.3904, -0.0893,  ..., -0.3033,  1.0024, -0.0396],\n",
      "        [ 1.3450,  1.6099, -0.2865,  ...,  1.8337, -0.6831,  1.0660],\n",
      "        ...,\n",
      "        [ 0.2281, -1.6177,  0.8695,  ...,  0.5702,  1.1325,  0.9541],\n",
      "        [-0.9425,  1.1783,  1.0604,  ...,  0.1450, -2.6185, -0.6543],\n",
      "        [-1.6862, -0.5303, -0.1794,  ..., -0.5043,  0.7093,  0.0709]],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: wpe.weight\n",
      "Shape: torch.Size([20, 64])\n",
      "Valores: Parameter containing:\n",
      "tensor([[ 0.9631,  1.9243,  1.1724,  ..., -0.0628, -0.1056,  0.5566],\n",
      "        [ 2.0910,  0.3645, -0.2723,  ...,  0.3509,  1.2313, -0.7659],\n",
      "        [ 0.1818, -0.3369, -0.3503,  ...,  0.7588, -0.8212,  1.2692],\n",
      "        ...,\n",
      "        [-0.8965, -2.3753,  0.7784,  ...,  1.1152,  0.1907,  0.0177],\n",
      "        [-0.0391, -1.3150,  1.8244,  ...,  0.1519,  1.5353, -0.4813],\n",
      "        [ 1.8777, -1.5917,  1.0685,  ...,  1.4522,  1.1898, -0.3012]],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: qkv_proj.0.weight\n",
      "Shape: torch.Size([192, 64])\n",
      "Valores: Parameter containing:\n",
      "tensor([[ 0.1167,  0.1198, -0.0525,  ...,  0.0999, -0.0835,  0.0481],\n",
      "        [ 0.0737,  0.0061,  0.0813,  ..., -0.1022,  0.0265, -0.0324],\n",
      "        [ 0.0527, -0.0611, -0.0908,  ..., -0.1012, -0.0491, -0.1177],\n",
      "        ...,\n",
      "        [ 0.0374,  0.0861, -0.0995,  ..., -0.1093, -0.1134, -0.0805],\n",
      "        [ 0.1162, -0.1181,  0.1221,  ..., -0.1099,  0.0709, -0.1030],\n",
      "        [-0.0365, -0.0328, -0.0839,  ..., -0.0442,  0.1133, -0.0593]],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: qkv_proj.0.bias\n",
      "Shape: torch.Size([192])\n",
      "Valores: Parameter containing:\n",
      "tensor([-0.0341, -0.1198, -0.0068, -0.0122, -0.1104, -0.0750, -0.0447,  0.0880,\n",
      "        -0.0660, -0.1120,  0.0234,  0.0716, -0.0895, -0.1116, -0.0378,  0.0611,\n",
      "        -0.0355,  0.0207, -0.0754, -0.0842,  0.0948,  0.0607, -0.1105, -0.0677,\n",
      "        -0.1202, -0.0365,  0.0360,  0.0802,  0.0283, -0.0903, -0.0667, -0.0667,\n",
      "         0.1193,  0.0600,  0.0437, -0.0345,  0.1150,  0.0250, -0.0594, -0.0318,\n",
      "         0.0547,  0.0787,  0.0814, -0.0857, -0.0323, -0.1084,  0.0747, -0.1240,\n",
      "        -0.0426,  0.0239,  0.0697,  0.0636,  0.0231, -0.1185, -0.1201,  0.1125,\n",
      "         0.0365,  0.0571,  0.0221,  0.0216, -0.0251, -0.0893,  0.0824,  0.0985,\n",
      "        -0.1147,  0.0821,  0.0627, -0.0958, -0.1083,  0.0431,  0.0387,  0.1162,\n",
      "         0.0312,  0.1120,  0.0283,  0.0010,  0.0115,  0.0129,  0.0612, -0.0032,\n",
      "        -0.0356, -0.0264,  0.0577,  0.0085, -0.0439, -0.0575,  0.0340,  0.0265,\n",
      "        -0.1017,  0.0904, -0.1185, -0.0619, -0.0530, -0.0106, -0.0797, -0.0391,\n",
      "        -0.0622, -0.1137, -0.0401,  0.0606,  0.0397, -0.0251, -0.0645, -0.0581,\n",
      "         0.0015, -0.0966,  0.1122, -0.0151, -0.0181, -0.0924,  0.0907,  0.0245,\n",
      "        -0.0508, -0.1249,  0.0309, -0.0373, -0.0685,  0.1123, -0.0877, -0.1234,\n",
      "         0.1126, -0.0055,  0.0449,  0.0012,  0.0770,  0.0638,  0.0922, -0.0669,\n",
      "         0.0564, -0.0089, -0.1149, -0.0265, -0.1238,  0.1235,  0.1168,  0.0775,\n",
      "         0.0932,  0.1039,  0.0061, -0.0788, -0.1078,  0.0914,  0.0799, -0.0243,\n",
      "         0.0637, -0.0743, -0.1049, -0.1211, -0.0269,  0.0892,  0.0370,  0.0670,\n",
      "        -0.0031, -0.0356,  0.0995, -0.1203, -0.0490, -0.0218,  0.0049,  0.0404,\n",
      "        -0.0333, -0.0476, -0.0959,  0.0504, -0.0517,  0.0954,  0.0027,  0.0847,\n",
      "         0.0098, -0.1138,  0.0645,  0.1217, -0.0155, -0.0608,  0.0266, -0.1102,\n",
      "         0.0265,  0.0289,  0.0472,  0.0323, -0.0482,  0.0759, -0.0477, -0.1071,\n",
      "         0.0435,  0.1243,  0.0352,  0.0710, -0.1070,  0.0830, -0.1155, -0.1155],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: qkv_proj.1.weight\n",
      "Shape: torch.Size([192, 64])\n",
      "Valores: Parameter containing:\n",
      "tensor([[-0.0736,  0.1193, -0.0341,  ...,  0.0194, -0.0170, -0.0547],\n",
      "        [ 0.0348,  0.0649,  0.1064,  ...,  0.0845,  0.0131, -0.0367],\n",
      "        [-0.1128, -0.0422,  0.1103,  ..., -0.0765, -0.0290,  0.0160],\n",
      "        ...,\n",
      "        [-0.1250, -0.0575,  0.0466,  ...,  0.0437,  0.0660, -0.0356],\n",
      "        [-0.1222, -0.1137,  0.0449,  ..., -0.0548, -0.0619,  0.1011],\n",
      "        [-0.0612,  0.0610, -0.0788,  ..., -0.0846, -0.1102,  0.0554]],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: qkv_proj.1.bias\n",
      "Shape: torch.Size([192])\n",
      "Valores: Parameter containing:\n",
      "tensor([ 0.0965,  0.1246,  0.0382,  0.0693, -0.0720, -0.0651,  0.0418,  0.0155,\n",
      "         0.0660, -0.0891, -0.0646, -0.0923, -0.0463,  0.0660,  0.0024,  0.1143,\n",
      "        -0.0600,  0.0225, -0.0461, -0.1052, -0.1155,  0.1173, -0.0014, -0.0289,\n",
      "        -0.0927,  0.0946,  0.0880,  0.1106,  0.0080,  0.0265,  0.0305, -0.0968,\n",
      "         0.0726,  0.1179, -0.1153,  0.0632,  0.0284,  0.0239,  0.0299,  0.0983,\n",
      "        -0.0936, -0.0447, -0.0995, -0.0378, -0.1026,  0.0269, -0.0544,  0.0003,\n",
      "         0.0931,  0.0865, -0.0421,  0.1200, -0.1221, -0.0154, -0.0942,  0.0055,\n",
      "         0.0904,  0.1058,  0.0946, -0.0204, -0.0515,  0.0663,  0.0128,  0.0575,\n",
      "         0.0763, -0.0486,  0.0314, -0.0677,  0.0761, -0.0956,  0.0943,  0.0354,\n",
      "        -0.0675, -0.0691,  0.0936,  0.0796,  0.0953,  0.0397,  0.1008,  0.0198,\n",
      "         0.0095, -0.0301, -0.1153, -0.0434, -0.0523,  0.0885, -0.0637, -0.0143,\n",
      "         0.0465, -0.0314,  0.0737, -0.0594, -0.0342,  0.0348,  0.0577, -0.0127,\n",
      "         0.0110,  0.0549,  0.0251, -0.0627, -0.1144,  0.0256, -0.0688, -0.0092,\n",
      "         0.0284, -0.0106, -0.0774, -0.0459,  0.0813,  0.1101, -0.0070,  0.0607,\n",
      "         0.1041,  0.0394, -0.0546,  0.1094, -0.0201, -0.0751,  0.0409, -0.0883,\n",
      "        -0.0431, -0.0341, -0.0484,  0.0975, -0.1222,  0.0873, -0.1245, -0.0774,\n",
      "         0.0196, -0.0425,  0.0761, -0.0310, -0.0840, -0.0830, -0.0281,  0.1199,\n",
      "         0.1241, -0.1156,  0.0815, -0.0964, -0.0710, -0.1100,  0.0429,  0.0227,\n",
      "        -0.1041, -0.0925, -0.0074,  0.0532, -0.0979,  0.0310,  0.0280, -0.0201,\n",
      "         0.0614, -0.0572, -0.1054,  0.0360,  0.0356,  0.0670,  0.0518, -0.1054,\n",
      "        -0.0657, -0.0450, -0.0564,  0.0888,  0.0474, -0.0291,  0.0833, -0.0101,\n",
      "         0.0138,  0.0541,  0.1110, -0.1136,  0.0261, -0.0134, -0.0505,  0.0223,\n",
      "         0.0583, -0.0883, -0.0215, -0.0440,  0.0125,  0.0496,  0.0172,  0.0952,\n",
      "         0.0656, -0.1090,  0.0308, -0.0878,  0.0757, -0.1211, -0.0974,  0.0550],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: qkv_proj.2.weight\n",
      "Shape: torch.Size([192, 64])\n",
      "Valores: Parameter containing:\n",
      "tensor([[ 0.0825,  0.0948,  0.0313,  ...,  0.1085, -0.0994,  0.1242],\n",
      "        [ 0.0567,  0.0015,  0.0375,  ..., -0.0726, -0.1143, -0.0528],\n",
      "        [-0.1180, -0.0464,  0.0469,  ..., -0.0867,  0.0303,  0.0649],\n",
      "        ...,\n",
      "        [ 0.1004,  0.1162, -0.0231,  ...,  0.1208, -0.0816,  0.0788],\n",
      "        [-0.1213, -0.1142,  0.0174,  ...,  0.0591, -0.0159, -0.0851],\n",
      "        [ 0.0807, -0.0717, -0.0483,  ..., -0.0616,  0.0294, -0.0919]],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: qkv_proj.2.bias\n",
      "Shape: torch.Size([192])\n",
      "Valores: Parameter containing:\n",
      "tensor([ 0.0023,  0.1204, -0.0937, -0.1155, -0.0351,  0.0963, -0.0699,  0.0342,\n",
      "        -0.1123,  0.0561,  0.1102,  0.0389,  0.1204, -0.0937,  0.0741, -0.0265,\n",
      "         0.0892,  0.0727, -0.0791,  0.0010,  0.0035, -0.0615, -0.0126,  0.0613,\n",
      "         0.1148, -0.0876, -0.0628, -0.0703,  0.1241,  0.0103, -0.0677,  0.0937,\n",
      "        -0.0109, -0.0449, -0.1105, -0.0313, -0.0550,  0.1197,  0.0373,  0.0985,\n",
      "         0.0123,  0.0767, -0.0174, -0.1130,  0.0486,  0.0817,  0.0672, -0.0217,\n",
      "         0.0253,  0.0654,  0.0941, -0.0887,  0.0932, -0.0243,  0.0198, -0.0327,\n",
      "         0.0777, -0.0179, -0.0884,  0.0282, -0.0904,  0.0572,  0.0729,  0.0196,\n",
      "        -0.0368, -0.0972, -0.1147,  0.0099, -0.0492,  0.0204, -0.0103, -0.0700,\n",
      "         0.0521, -0.1073,  0.0131, -0.0207, -0.0634, -0.0036,  0.0111, -0.0870,\n",
      "         0.1146, -0.0615, -0.0308,  0.0563,  0.0622, -0.0615,  0.0874, -0.0623,\n",
      "        -0.0881,  0.0687, -0.1179, -0.0244, -0.0717,  0.0317, -0.0397, -0.1047,\n",
      "         0.0961,  0.0572, -0.1211,  0.0634,  0.0525,  0.0273, -0.0313, -0.0517,\n",
      "         0.0500, -0.1092, -0.0234, -0.1053, -0.0230, -0.0446, -0.0628, -0.0639,\n",
      "        -0.0860,  0.0735,  0.0553,  0.0944, -0.0214,  0.0806, -0.0965, -0.0916,\n",
      "         0.0098, -0.0462,  0.0016,  0.0141, -0.0617,  0.0136, -0.0350, -0.0629,\n",
      "         0.0886,  0.1008,  0.0517, -0.0282,  0.1174,  0.0875, -0.0965,  0.0056,\n",
      "        -0.0939,  0.0207, -0.0893,  0.0087, -0.0326,  0.0189, -0.0595, -0.0110,\n",
      "        -0.0313, -0.1222, -0.0153,  0.0942, -0.1142, -0.0928, -0.1207, -0.0258,\n",
      "         0.0618, -0.0302, -0.0116,  0.0164, -0.0663, -0.0676, -0.0709,  0.1237,\n",
      "        -0.0315, -0.1067, -0.0308,  0.0195,  0.1214,  0.0357, -0.1009, -0.0032,\n",
      "         0.1120, -0.0767,  0.0515,  0.0588, -0.0173,  0.0748, -0.1063, -0.0026,\n",
      "        -0.0209, -0.0784, -0.1157, -0.1115, -0.0718, -0.0293,  0.0347, -0.0467,\n",
      "         0.0996,  0.0884,  0.0151, -0.0813,  0.0235, -0.0868,  0.0547, -0.0299],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: out_proj.0.weight\n",
      "Shape: torch.Size([64, 64])\n",
      "Valores: Parameter containing:\n",
      "tensor([[ 0.0994,  0.1200, -0.0321,  ...,  0.0122,  0.0435, -0.0694],\n",
      "        [ 0.0274, -0.0542, -0.1134,  ...,  0.1207, -0.0134,  0.1147],\n",
      "        [-0.0692, -0.1044,  0.0477,  ...,  0.0177, -0.0637, -0.0493],\n",
      "        ...,\n",
      "        [ 0.0888, -0.0016, -0.1022,  ..., -0.0088,  0.0869,  0.1042],\n",
      "        [ 0.0614, -0.1004,  0.1001,  ..., -0.1121,  0.1092,  0.0572],\n",
      "        [-0.0709,  0.0603,  0.0673,  ...,  0.0594, -0.0400, -0.0693]],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: out_proj.0.bias\n",
      "Shape: torch.Size([64])\n",
      "Valores: Parameter containing:\n",
      "tensor([ 0.1023, -0.0075, -0.0995,  0.0384,  0.0212, -0.0270, -0.0318, -0.0066,\n",
      "         0.0426,  0.0756, -0.0341,  0.0944,  0.0558, -0.0829,  0.0232,  0.0381,\n",
      "         0.0601, -0.1068, -0.0680,  0.0428,  0.1038, -0.0773,  0.1121,  0.0787,\n",
      "         0.0592, -0.0325,  0.0708, -0.0375, -0.0707, -0.0143,  0.0997,  0.0738,\n",
      "         0.0525,  0.0508,  0.0122,  0.0866, -0.0045, -0.0875, -0.0056,  0.0924,\n",
      "        -0.0783, -0.0103,  0.0130,  0.0756,  0.0151,  0.0852, -0.1042,  0.0695,\n",
      "         0.0740,  0.0771,  0.0017,  0.0746, -0.0722,  0.0182,  0.0388, -0.0624,\n",
      "         0.0567, -0.0554,  0.0698,  0.0130,  0.0676,  0.0663,  0.0067, -0.0051],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: out_proj.1.weight\n",
      "Shape: torch.Size([64, 64])\n",
      "Valores: Parameter containing:\n",
      "tensor([[ 0.1052,  0.0442,  0.0093,  ...,  0.1209, -0.0108, -0.0747],\n",
      "        [-0.0836,  0.0697,  0.1064,  ..., -0.0596, -0.0665, -0.0447],\n",
      "        [-0.0800, -0.0661,  0.0523,  ...,  0.1008, -0.0755, -0.1164],\n",
      "        ...,\n",
      "        [-0.0507, -0.0210,  0.0021,  ..., -0.0104,  0.0156,  0.0477],\n",
      "        [-0.0139,  0.0440, -0.0212,  ..., -0.0705, -0.0270,  0.1067],\n",
      "        [ 0.0352,  0.1083, -0.0273,  ..., -0.0656, -0.0879, -0.0485]],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: out_proj.1.bias\n",
      "Shape: torch.Size([64])\n",
      "Valores: Parameter containing:\n",
      "tensor([ 0.0140,  0.0049, -0.0243, -0.1108,  0.0312,  0.0452,  0.1115, -0.1162,\n",
      "        -0.0469,  0.0894,  0.0168,  0.0840, -0.0177,  0.1031,  0.0352,  0.1062,\n",
      "        -0.0174, -0.0885, -0.0670, -0.0496,  0.0633, -0.0379,  0.0485, -0.0185,\n",
      "        -0.0169, -0.0429, -0.0445, -0.0359,  0.0293,  0.1156,  0.1096, -0.0199,\n",
      "        -0.0185,  0.1063,  0.0954,  0.0179,  0.0700, -0.0503, -0.1237,  0.0724,\n",
      "        -0.1125, -0.0015, -0.0797,  0.0177, -0.1220,  0.0722, -0.0669, -0.1177,\n",
      "        -0.1248,  0.0048, -0.0933, -0.0391, -0.0677, -0.0897,  0.0978, -0.1045,\n",
      "         0.1025, -0.0088,  0.0433, -0.0031,  0.1036, -0.0936,  0.1235, -0.0452],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: out_proj.2.weight\n",
      "Shape: torch.Size([64, 64])\n",
      "Valores: Parameter containing:\n",
      "tensor([[-0.0497, -0.0426, -0.1125,  ..., -0.0119,  0.1021,  0.1165],\n",
      "        [-0.1080, -0.0999, -0.0844,  ..., -0.0862,  0.0218, -0.0911],\n",
      "        [-0.0811, -0.0525,  0.0706,  ...,  0.1147, -0.1022,  0.0610],\n",
      "        ...,\n",
      "        [ 0.0957, -0.0694,  0.0374,  ..., -0.1008,  0.0862,  0.0158],\n",
      "        [ 0.0871, -0.0258, -0.0318,  ..., -0.0952,  0.0576,  0.1118],\n",
      "        [-0.0451,  0.1231,  0.0387,  ...,  0.1051, -0.0845, -0.1215]],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: out_proj.2.bias\n",
      "Shape: torch.Size([64])\n",
      "Valores: Parameter containing:\n",
      "tensor([-0.0685,  0.0261,  0.0541, -0.1084,  0.0657,  0.0414, -0.0590,  0.0901,\n",
      "         0.0924, -0.1035, -0.0698,  0.1182, -0.0465, -0.0625, -0.1134, -0.0809,\n",
      "        -0.0068, -0.1045, -0.1142,  0.0533,  0.1210, -0.0049,  0.0016, -0.0090,\n",
      "         0.1222, -0.0266,  0.0863,  0.0554,  0.0021, -0.1019,  0.0148,  0.1116,\n",
      "         0.1171, -0.0106, -0.0334,  0.1048,  0.0060,  0.0489,  0.0003, -0.0876,\n",
      "         0.0148,  0.0230, -0.0445, -0.0244, -0.0653, -0.1107, -0.0355,  0.0341,\n",
      "        -0.0222,  0.0207,  0.0058,  0.1239,  0.0768, -0.0070, -0.0205,  0.0285,\n",
      "         0.0059,  0.0715, -0.0241, -0.0392, -0.1204,  0.0271,  0.0527, -0.0830],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: mlp.0.0.weight\n",
      "Shape: torch.Size([128, 64])\n",
      "Valores: Parameter containing:\n",
      "tensor([[ 0.0020, -0.1004, -0.1219,  ..., -0.0265,  0.0591,  0.0674],\n",
      "        [ 0.0623,  0.0154, -0.0197,  ..., -0.0981,  0.0839, -0.0533],\n",
      "        [-0.1214,  0.0651, -0.0900,  ...,  0.1049, -0.0629, -0.0152],\n",
      "        ...,\n",
      "        [-0.0040,  0.0897,  0.0868,  ..., -0.0086,  0.0971, -0.0568],\n",
      "        [ 0.0419, -0.0090,  0.0018,  ..., -0.1003,  0.1062, -0.0150],\n",
      "        [-0.0879,  0.1243, -0.0097,  ..., -0.1037,  0.0958, -0.0823]],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: mlp.0.0.bias\n",
      "Shape: torch.Size([128])\n",
      "Valores: Parameter containing:\n",
      "tensor([ 0.0400,  0.1101, -0.0892,  0.0302,  0.0764,  0.0285,  0.0968,  0.0320,\n",
      "        -0.0469, -0.0467,  0.0160, -0.1022, -0.0786, -0.0530, -0.1065, -0.0828,\n",
      "        -0.0971, -0.0279, -0.0443,  0.0572, -0.0313,  0.0872, -0.0865, -0.0005,\n",
      "        -0.1084, -0.1195,  0.0337,  0.0426,  0.0035, -0.0033, -0.1007,  0.0146,\n",
      "        -0.0514, -0.0709,  0.1006,  0.0022,  0.1126, -0.0090, -0.0426,  0.0468,\n",
      "         0.0475, -0.0199, -0.0870,  0.0818, -0.0780,  0.1171,  0.0632, -0.0017,\n",
      "        -0.0030, -0.1140, -0.0939,  0.1176, -0.0070,  0.0016, -0.0456,  0.0177,\n",
      "         0.1244,  0.1194, -0.0611,  0.0432, -0.0893,  0.1010,  0.0817, -0.0477,\n",
      "         0.0010,  0.0950,  0.0493,  0.0960, -0.0346, -0.0029,  0.0913,  0.0362,\n",
      "         0.0057,  0.0821,  0.0526, -0.0584, -0.0876, -0.0034, -0.1038,  0.0764,\n",
      "         0.0024,  0.0041,  0.0069,  0.0036, -0.1148,  0.0808,  0.0511,  0.0851,\n",
      "        -0.0106, -0.0131,  0.1039, -0.1005,  0.1223, -0.0757,  0.1235, -0.0548,\n",
      "        -0.0397, -0.0134,  0.0038, -0.0202,  0.0605,  0.0811, -0.1155,  0.1088,\n",
      "         0.1105, -0.0939, -0.1033, -0.1114, -0.1008, -0.0012,  0.0994, -0.0337,\n",
      "        -0.0383, -0.1064,  0.0758, -0.0554, -0.1008, -0.0336, -0.0647, -0.1185,\n",
      "         0.0792,  0.0473, -0.0696, -0.0478, -0.0543, -0.1125,  0.1084,  0.0684],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: mlp.0.2.weight\n",
      "Shape: torch.Size([64, 128])\n",
      "Valores: Parameter containing:\n",
      "tensor([[ 0.0234,  0.0416, -0.0516,  ...,  0.0745,  0.0795,  0.0341],\n",
      "        [ 0.0259,  0.0850, -0.0127,  ..., -0.0423, -0.0073,  0.0340],\n",
      "        [-0.0862,  0.0492, -0.0611,  ..., -0.0727,  0.0820, -0.0454],\n",
      "        ...,\n",
      "        [ 0.0078, -0.0537,  0.0682,  ..., -0.0545, -0.0055,  0.0699],\n",
      "        [-0.0572, -0.0731, -0.0430,  ..., -0.0681, -0.0557,  0.0040],\n",
      "        [ 0.0212,  0.0822, -0.0562,  ...,  0.0406,  0.0716, -0.0594]],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: mlp.0.2.bias\n",
      "Shape: torch.Size([64])\n",
      "Valores: Parameter containing:\n",
      "tensor([ 0.0484, -0.0552,  0.0849, -0.0332,  0.0751,  0.0763,  0.0788, -0.0647,\n",
      "         0.0192,  0.0810,  0.0859, -0.0774,  0.0282,  0.0531, -0.0844, -0.0528,\n",
      "         0.0150, -0.0090, -0.0757,  0.0709,  0.0756, -0.0248, -0.0460, -0.0172,\n",
      "         0.0326, -0.0313,  0.0664, -0.0367,  0.0212, -0.0675,  0.0368,  0.0382,\n",
      "        -0.0323, -0.0268, -0.0564,  0.0745, -0.0249,  0.0046, -0.0828,  0.0379,\n",
      "        -0.0850, -0.0643,  0.0845, -0.0384, -0.0182,  0.0023,  0.0660, -0.0338,\n",
      "        -0.0825,  0.0624,  0.0704,  0.0843, -0.0133,  0.0573,  0.0637, -0.0384,\n",
      "         0.0371, -0.0832,  0.0138,  0.0363, -0.0167, -0.0880,  0.0792, -0.0482],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: mlp.1.0.weight\n",
      "Shape: torch.Size([128, 64])\n",
      "Valores: Parameter containing:\n",
      "tensor([[-0.0724, -0.0408,  0.1077,  ..., -0.1228,  0.0046, -0.0414],\n",
      "        [-0.0099,  0.1039,  0.1072,  ..., -0.0642, -0.0314, -0.1058],\n",
      "        [-0.0833, -0.0888, -0.0467,  ..., -0.0079,  0.0427,  0.0992],\n",
      "        ...,\n",
      "        [-0.1072,  0.0442,  0.0027,  ...,  0.0915, -0.0742,  0.0783],\n",
      "        [-0.0111, -0.0411, -0.0036,  ..., -0.0322, -0.0883,  0.1092],\n",
      "        [ 0.0316, -0.0022,  0.0095,  ...,  0.0954, -0.1213,  0.0180]],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: mlp.1.0.bias\n",
      "Shape: torch.Size([128])\n",
      "Valores: Parameter containing:\n",
      "tensor([ 5.5304e-02, -4.3423e-02,  9.0208e-02,  2.4091e-03,  1.2077e-01,\n",
      "        -1.2094e-01, -7.0503e-02, -8.7078e-02, -4.7968e-02,  8.2578e-02,\n",
      "         1.0956e-02, -1.2107e-01, -3.2673e-02, -5.3264e-02,  4.5960e-03,\n",
      "         1.9634e-02,  1.1749e-01, -3.4146e-02,  1.1146e-01, -4.0702e-02,\n",
      "         5.7042e-02,  6.2568e-02, -6.7964e-02,  1.1377e-01, -6.7434e-02,\n",
      "        -6.1582e-02, -4.4202e-02,  1.0919e-01,  9.3198e-02, -1.5819e-02,\n",
      "        -7.6657e-02,  1.2219e-01, -1.0692e-01, -8.9537e-02, -9.0747e-02,\n",
      "         1.1976e-02,  4.2885e-02, -1.0560e-01, -3.5822e-02,  4.6407e-02,\n",
      "         4.6203e-02, -5.3266e-02,  6.7542e-02,  1.3787e-02, -7.5380e-02,\n",
      "        -6.2267e-02, -4.4823e-05, -2.1329e-02,  7.3154e-02, -8.0250e-02,\n",
      "        -3.4763e-02, -1.9901e-02, -9.0924e-03,  1.2449e-01, -7.3916e-02,\n",
      "         3.9433e-02, -1.1723e-02, -2.2841e-02, -4.9765e-02,  1.2183e-01,\n",
      "        -4.1655e-02,  9.2335e-02,  1.2182e-01, -7.8128e-03, -7.9404e-02,\n",
      "         3.1148e-02,  6.0283e-02,  2.9983e-02,  1.8644e-02,  5.0029e-02,\n",
      "        -3.5042e-02,  1.5953e-02, -1.2395e-01, -1.7769e-02,  7.9570e-03,\n",
      "        -6.7029e-03,  9.5262e-02, -7.9166e-02,  1.2456e-01, -1.1834e-01,\n",
      "         8.3453e-02,  9.1024e-02,  8.2790e-02, -1.5941e-02,  4.5399e-02,\n",
      "        -7.4833e-02,  1.1239e-02, -8.7024e-02, -5.8813e-03, -7.2513e-02,\n",
      "        -8.8499e-02, -8.4506e-02, -2.9467e-02, -8.9653e-02,  1.0406e-01,\n",
      "         1.2150e-01, -9.2198e-02, -1.2418e-01,  3.7905e-02,  6.4783e-02,\n",
      "        -2.9741e-02,  1.1020e-01,  7.6718e-02,  1.9677e-02, -1.1928e-01,\n",
      "         1.8348e-02, -1.1706e-01, -1.1396e-01,  4.9274e-02, -6.2552e-02,\n",
      "        -7.9009e-02,  8.2658e-02,  3.9181e-02, -1.0812e-03, -1.1219e-01,\n",
      "        -4.0664e-02, -7.3287e-02,  5.1478e-02, -1.0437e-01, -1.2101e-01,\n",
      "        -5.2066e-02, -2.5302e-02,  1.6043e-02, -1.6690e-02, -8.7321e-02,\n",
      "         3.0897e-02,  1.1977e-01, -8.3666e-02], requires_grad=True)\n",
      "\n",
      "Nome: mlp.1.2.weight\n",
      "Shape: torch.Size([64, 128])\n",
      "Valores: Parameter containing:\n",
      "tensor([[-0.0213, -0.0373,  0.0758,  ...,  0.0225,  0.0668, -0.0711],\n",
      "        [ 0.0697, -0.0840, -0.0633,  ..., -0.0047, -0.0369, -0.0723],\n",
      "        [ 0.0067, -0.0036,  0.0658,  ...,  0.0809,  0.0186, -0.0587],\n",
      "        ...,\n",
      "        [-0.0065, -0.0869, -0.0100,  ...,  0.0009,  0.0199, -0.0564],\n",
      "        [ 0.0767, -0.0048,  0.0462,  ...,  0.0715, -0.0878, -0.0138],\n",
      "        [ 0.0071,  0.0471, -0.0468,  ...,  0.0628, -0.0701,  0.0618]],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: mlp.1.2.bias\n",
      "Shape: torch.Size([64])\n",
      "Valores: Parameter containing:\n",
      "tensor([-0.0049, -0.0210, -0.0101,  0.0043, -0.0197,  0.0767,  0.0019, -0.0121,\n",
      "         0.0182,  0.0743,  0.0683, -0.0218,  0.0395, -0.0583, -0.0589, -0.0098,\n",
      "        -0.0598,  0.0236,  0.0227, -0.0854,  0.0301,  0.0387,  0.0695, -0.0348,\n",
      "         0.0479, -0.0504, -0.0603, -0.0834, -0.0434, -0.0749, -0.0135,  0.0053,\n",
      "         0.0546,  0.0576,  0.0459, -0.0133, -0.0685,  0.0446,  0.0118,  0.0014,\n",
      "         0.0705, -0.0158,  0.0010, -0.0111, -0.0336, -0.0406,  0.0311, -0.0880,\n",
      "         0.0177, -0.0108, -0.0603, -0.0610, -0.0741,  0.0112,  0.0266,  0.0055,\n",
      "         0.0876, -0.0638, -0.0092, -0.0233, -0.0179, -0.0836,  0.0638, -0.0509],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: mlp.2.0.weight\n",
      "Shape: torch.Size([128, 64])\n",
      "Valores: Parameter containing:\n",
      "tensor([[ 0.0927, -0.0188, -0.1100,  ...,  0.0084,  0.0786, -0.0100],\n",
      "        [-0.0796,  0.0069, -0.1132,  ..., -0.0192, -0.0733,  0.0489],\n",
      "        [ 0.0743, -0.0187, -0.0296,  ...,  0.0465, -0.0611,  0.0263],\n",
      "        ...,\n",
      "        [ 0.0129,  0.0630, -0.1077,  ..., -0.0308, -0.0812,  0.0042],\n",
      "        [ 0.1108,  0.0895,  0.1199,  ..., -0.0288, -0.0143,  0.1230],\n",
      "        [-0.0155, -0.1237, -0.1035,  ..., -0.0923,  0.0229, -0.0725]],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: mlp.2.0.bias\n",
      "Shape: torch.Size([128])\n",
      "Valores: Parameter containing:\n",
      "tensor([-0.0080,  0.0826, -0.0901,  0.0039, -0.0240, -0.0587, -0.1227,  0.0303,\n",
      "        -0.0198,  0.0857, -0.0626, -0.0217, -0.1076, -0.0612, -0.0099, -0.0033,\n",
      "        -0.0550, -0.0580, -0.0921, -0.0137,  0.0132, -0.0437, -0.0877,  0.0353,\n",
      "        -0.0842, -0.1215, -0.1222,  0.1036,  0.0374,  0.0866, -0.0660, -0.0713,\n",
      "        -0.0649,  0.0040,  0.0544, -0.1212,  0.0217,  0.0523, -0.0595, -0.0874,\n",
      "         0.0010,  0.0915,  0.0964,  0.0011,  0.0464, -0.0972, -0.0050,  0.0388,\n",
      "         0.0783, -0.0964, -0.0515,  0.0488, -0.0874,  0.0651,  0.0495, -0.0748,\n",
      "         0.1110,  0.0801,  0.0774,  0.0326, -0.0970, -0.1067,  0.0350,  0.0173,\n",
      "        -0.0240,  0.0609, -0.0611,  0.1063,  0.1153, -0.0111,  0.1081, -0.0267,\n",
      "        -0.0787,  0.0982,  0.0517,  0.1083, -0.0079,  0.0414,  0.0561, -0.0019,\n",
      "        -0.1018,  0.0585, -0.0734, -0.0195,  0.0893,  0.0703, -0.0982,  0.0807,\n",
      "        -0.0926,  0.0139, -0.0425, -0.0567,  0.0699, -0.1247, -0.1154,  0.0964,\n",
      "        -0.1151, -0.0977, -0.0222, -0.0544,  0.0377, -0.0458, -0.0833, -0.0441,\n",
      "        -0.0550, -0.0250, -0.0417,  0.0712, -0.1106, -0.0356, -0.0030, -0.0010,\n",
      "         0.0749, -0.0479,  0.0678,  0.0559, -0.1175, -0.1130,  0.0703, -0.0702,\n",
      "        -0.0081, -0.0843, -0.0960, -0.0478, -0.1111,  0.0819,  0.0651,  0.0789],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: mlp.2.2.weight\n",
      "Shape: torch.Size([64, 128])\n",
      "Valores: Parameter containing:\n",
      "tensor([[-0.0287, -0.0021,  0.0010,  ..., -0.0079,  0.0257,  0.0433],\n",
      "        [ 0.0388, -0.0495,  0.0250,  ...,  0.0878,  0.0399,  0.0664],\n",
      "        [-0.0245,  0.0057,  0.0486,  ..., -0.0171,  0.0005,  0.0146],\n",
      "        ...,\n",
      "        [-0.0785,  0.0698, -0.0013,  ..., -0.0594, -0.0773, -0.0650],\n",
      "        [-0.0523, -0.0074, -0.0227,  ...,  0.0702, -0.0005, -0.0049],\n",
      "        [-0.0295,  0.0823,  0.0816,  ..., -0.0876,  0.0196,  0.0246]],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: mlp.2.2.bias\n",
      "Shape: torch.Size([64])\n",
      "Valores: Parameter containing:\n",
      "tensor([ 0.0067,  0.0232,  0.0305,  0.0478,  0.0284,  0.0541, -0.0536,  0.0589,\n",
      "        -0.0480,  0.0834,  0.0217,  0.0825,  0.0195,  0.0505,  0.0657, -0.0679,\n",
      "         0.0868,  0.0790, -0.0839, -0.0745, -0.0504, -0.0685, -0.0024,  0.0307,\n",
      "        -0.0323,  0.0874,  0.0660, -0.0777,  0.0787, -0.0008, -0.0688,  0.0805,\n",
      "        -0.0248, -0.0071, -0.0559, -0.0120,  0.0340,  0.0457, -0.0341,  0.0809,\n",
      "        -0.0067,  0.0672, -0.0644,  0.0078,  0.0040, -0.0575, -0.0135, -0.0524,\n",
      "        -0.0229,  0.0789, -0.0353,  0.0336, -0.0768,  0.0157,  0.0135,  0.0161,\n",
      "         0.0508,  0.0758, -0.0273,  0.0158, -0.0617,  0.0454, -0.0561, -0.0023],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: ln.weight\n",
      "Shape: torch.Size([64])\n",
      "Valores: Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "\n",
      "Nome: ln.bias\n",
      "Shape: torch.Size([64])\n",
      "Valores: Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "Nome: lm_head.weight\n",
      "Shape: torch.Size([529, 64])\n",
      "Valores: Parameter containing:\n",
      "tensor([[-0.0419, -0.0166,  0.0088,  ...,  0.1061, -0.0986, -0.0621],\n",
      "        [ 0.0963, -0.0732,  0.0909,  ...,  0.0484,  0.0715, -0.0571],\n",
      "        [ 0.0576, -0.0495,  0.0240,  ...,  0.0625, -0.0297, -0.0220],\n",
      "        ...,\n",
      "        [ 0.0939,  0.0702, -0.0447,  ...,  0.0257,  0.0707,  0.0462],\n",
      "        [-0.0837, -0.0422,  0.0729,  ...,  0.0506,  0.0440,  0.0381],\n",
      "        [-0.0514,  0.0392,  0.0549,  ...,  0.0347, -0.0002,  0.1011]],\n",
      "       requires_grad=True)\n",
      "\n",
      "Nome: lm_head.bias\n",
      "Shape: torch.Size([529])\n",
      "Valores: Parameter containing:\n",
      "tensor([-6.6122e-02, -1.1639e-01, -8.3089e-05, -1.3133e-02,  3.4617e-02,\n",
      "        -1.0318e-01,  5.8381e-02, -2.4334e-02, -6.7161e-02,  5.6497e-02,\n",
      "        -2.2886e-02, -3.1351e-02,  3.4583e-02,  8.4089e-02,  9.4939e-02,\n",
      "         1.0711e-01, -5.7817e-02,  1.3927e-02, -4.7285e-02, -1.2415e-01,\n",
      "         2.6990e-02,  1.1320e-01, -4.2530e-02,  1.0312e-01, -4.6024e-02,\n",
      "        -1.0540e-01, -4.5696e-02,  3.3446e-02, -1.0301e-01, -1.9868e-02,\n",
      "        -3.9991e-02, -7.7360e-03, -8.1400e-02, -1.2281e-01, -3.2641e-02,\n",
      "        -1.2300e-02,  4.6082e-02,  2.1876e-02, -1.6947e-02, -8.1922e-02,\n",
      "         1.0360e-01,  1.1853e-01, -4.0631e-02,  8.4706e-02,  8.6531e-02,\n",
      "        -1.0289e-01,  1.0109e-01, -8.1045e-02,  1.2967e-02,  2.5515e-02,\n",
      "        -3.7734e-02, -1.3617e-02, -4.2170e-02,  1.1696e-01,  1.1108e-01,\n",
      "        -2.9920e-02,  1.8477e-02, -1.1991e-01,  4.9969e-02, -3.3699e-02,\n",
      "        -6.4099e-02, -3.2150e-02,  2.8629e-02,  9.5695e-03, -8.7200e-02,\n",
      "        -8.4385e-02, -1.0909e-01,  1.0315e-01,  6.1076e-02,  1.0972e-01,\n",
      "         2.9832e-03,  3.4001e-02,  4.1274e-03,  5.6525e-02,  9.7113e-02,\n",
      "        -2.8507e-02, -8.3710e-02, -3.4436e-02, -4.5615e-02,  3.0342e-03,\n",
      "         1.0650e-01, -4.2141e-02, -2.5750e-03,  1.9932e-02, -7.7641e-02,\n",
      "         3.6077e-02, -1.1920e-01,  1.0282e-01, -5.6208e-02, -8.2346e-02,\n",
      "         8.9820e-02,  1.1232e-01,  6.6166e-02,  1.1620e-01, -8.6608e-02,\n",
      "        -6.5953e-02,  8.6284e-02,  9.0178e-02, -6.6978e-02, -8.0364e-02,\n",
      "        -5.0811e-02,  1.7696e-03, -1.9749e-02, -3.7521e-02, -1.0278e-01,\n",
      "        -6.8365e-02, -1.2073e-01,  2.4842e-02,  2.3053e-02, -4.5255e-02,\n",
      "         1.2193e-01,  5.7091e-02, -1.1612e-03, -2.0129e-02,  3.4573e-03,\n",
      "        -9.3549e-02, -3.4725e-02, -2.7688e-02, -9.4668e-02, -7.4691e-02,\n",
      "        -6.5187e-02, -9.8205e-02, -7.5215e-02, -1.1125e-01, -2.8979e-02,\n",
      "        -8.1426e-02, -9.7422e-02,  2.7091e-02, -6.4488e-02, -5.9243e-02,\n",
      "         7.1914e-02, -4.2185e-02, -4.4922e-02,  1.1741e-01, -3.4136e-02,\n",
      "         2.6948e-02,  1.1819e-01,  9.4131e-02, -4.0103e-02,  2.3821e-02,\n",
      "        -4.6731e-02,  5.3895e-02,  4.5000e-02,  7.6213e-02,  3.3213e-02,\n",
      "        -1.1008e-02, -5.4986e-02,  6.3052e-02,  7.2437e-02,  2.2913e-02,\n",
      "         1.1076e-01,  1.1782e-01,  2.6583e-02,  2.2231e-03,  3.0772e-02,\n",
      "         9.6138e-02, -7.8352e-02, -1.1599e-01,  1.0877e-01, -8.1925e-02,\n",
      "        -9.3634e-02, -1.0905e-01,  5.8884e-02, -2.9536e-02,  5.1575e-02,\n",
      "        -8.4797e-02,  1.3544e-02,  2.5548e-02, -2.1006e-02,  1.9805e-02,\n",
      "         2.6833e-02, -6.6314e-03, -8.5698e-02, -1.1216e-01,  3.1549e-02,\n",
      "        -8.0363e-02, -9.1629e-02, -9.4232e-02, -1.0770e-01,  5.3370e-02,\n",
      "        -5.0322e-02,  5.0002e-03, -1.0529e-01,  5.4489e-02,  7.2205e-02,\n",
      "         1.0815e-01,  4.2458e-02, -9.9088e-02, -1.1786e-02, -6.2729e-02,\n",
      "        -9.6894e-02, -1.0341e-01,  2.4195e-02, -7.7594e-02, -1.0954e-02,\n",
      "        -1.1323e-01,  3.6944e-02,  8.0357e-02, -6.3896e-02,  1.2375e-01,\n",
      "         5.2871e-03, -9.5351e-02, -6.6676e-02, -1.0413e-01,  9.6296e-02,\n",
      "        -5.7586e-02,  2.9879e-02,  4.6282e-02,  7.0344e-02,  1.9899e-02,\n",
      "         1.0258e-01,  1.0434e-02, -9.7082e-02,  4.8478e-02,  4.0579e-02,\n",
      "        -3.7695e-02,  9.3259e-02,  1.5057e-02,  8.3367e-02,  6.8058e-02,\n",
      "         7.2891e-02, -1.1433e-01, -5.4379e-02, -1.2139e-02, -2.2690e-02,\n",
      "         1.0717e-01,  4.8315e-02,  3.6850e-02, -5.6822e-02, -4.6537e-02,\n",
      "        -3.0588e-02, -9.7866e-02,  5.4359e-02,  7.5432e-02, -3.1219e-02,\n",
      "        -2.8850e-02, -9.9248e-02,  7.1107e-02, -5.1525e-02,  9.5653e-03,\n",
      "        -4.8653e-02, -9.8638e-03,  8.9526e-02,  5.3202e-02, -1.0933e-01,\n",
      "         2.8896e-02, -8.2162e-02,  2.5175e-02,  3.2590e-02,  5.9728e-02,\n",
      "         7.1441e-02,  7.6734e-03,  8.8736e-02, -1.3179e-02,  4.6750e-02,\n",
      "         1.0037e-01, -9.2126e-02,  5.3751e-02,  4.3648e-02, -4.2604e-02,\n",
      "         6.7154e-02,  1.0319e-01, -3.2125e-02,  6.5578e-02,  1.0047e-01,\n",
      "        -5.5959e-02, -9.8328e-02, -7.7291e-02,  7.7487e-02,  3.6344e-03,\n",
      "         9.7163e-02,  8.6134e-02, -7.4239e-02, -8.9201e-02,  9.1552e-02,\n",
      "        -9.8891e-02, -7.7950e-02,  3.3448e-02, -2.9475e-02, -6.6085e-02,\n",
      "         8.8107e-02, -5.8317e-02,  1.0561e-01,  1.1218e-01,  1.8618e-02,\n",
      "        -7.2174e-02,  1.1231e-01,  8.9562e-02,  1.1242e-01,  1.0595e-01,\n",
      "        -1.1276e-01, -2.9006e-02, -9.2573e-02,  4.2362e-03, -4.2795e-02,\n",
      "         9.6696e-02, -7.8058e-02, -1.1775e-01,  2.4345e-02,  2.0364e-02,\n",
      "         8.1203e-02, -2.2614e-02,  1.0241e-02, -3.6204e-02, -1.9292e-03,\n",
      "         8.9994e-02, -8.9342e-02,  7.4713e-02,  5.1684e-02, -9.0870e-02,\n",
      "         1.2073e-01, -4.6591e-02, -3.6406e-02, -6.3225e-02,  7.3698e-02,\n",
      "        -4.1075e-02, -6.5310e-02,  1.1282e-01,  1.2421e-01,  3.3165e-02,\n",
      "         2.9678e-02, -6.2251e-02,  7.1615e-02, -3.0246e-02,  1.0360e-01,\n",
      "         4.5383e-02,  1.0046e-01, -4.5894e-02, -1.0764e-01,  1.5268e-02,\n",
      "         6.5620e-02,  1.1292e-01, -7.2845e-02,  4.9083e-02, -5.7822e-02,\n",
      "         1.8997e-02,  7.8633e-02,  3.4076e-02, -7.8568e-02,  5.6453e-02,\n",
      "         3.5908e-02,  8.5588e-02,  5.3597e-02,  6.8371e-03, -1.2276e-04,\n",
      "         2.9798e-02,  1.8552e-02,  4.1320e-02,  1.6114e-02, -4.9661e-02,\n",
      "         6.3671e-02,  6.1894e-02, -8.9829e-02, -1.1676e-02, -2.0102e-02,\n",
      "         4.5610e-02,  3.8292e-02,  1.1528e-01,  1.2393e-03, -1.9581e-02,\n",
      "         7.7597e-02, -6.7678e-04, -5.3853e-02, -1.1072e-03,  9.2274e-02,\n",
      "        -1.2173e-01, -2.3786e-02, -5.4159e-02, -6.3553e-02, -7.9270e-02,\n",
      "        -4.9338e-02,  6.5134e-02, -1.0772e-01,  4.8896e-02, -1.2158e-01,\n",
      "        -1.0353e-01, -7.5743e-02,  7.5399e-02,  4.2992e-02, -8.0735e-02,\n",
      "         8.4996e-02, -4.3269e-02, -9.1274e-03,  4.9849e-02, -4.7733e-02,\n",
      "        -8.7589e-02,  1.0007e-01, -1.3192e-02, -1.1212e-01,  8.7529e-02,\n",
      "        -7.4779e-02, -5.2469e-02, -1.5179e-03,  1.1401e-01, -1.0563e-01,\n",
      "        -4.6578e-04, -9.5795e-02,  4.2851e-02, -1.7794e-02,  1.0727e-01,\n",
      "         1.2304e-02,  2.1898e-02,  3.8025e-02,  1.0883e-02,  1.2145e-01,\n",
      "        -7.3573e-02, -9.2143e-02, -7.6427e-02, -9.7475e-02, -2.2053e-02,\n",
      "         1.7214e-02, -2.3401e-02, -1.1830e-01,  1.1473e-01,  1.0864e-01,\n",
      "        -2.4143e-02, -8.5628e-02, -2.3759e-02, -1.0191e-02, -5.8410e-02,\n",
      "         6.1273e-02, -2.2370e-02,  8.6780e-04,  1.2202e-01,  8.7440e-02,\n",
      "        -8.1034e-02, -1.2140e-01,  4.1425e-02, -7.6785e-03,  7.5190e-02,\n",
      "        -3.0842e-02, -5.8159e-02,  7.0392e-02,  1.0700e-01,  8.7329e-02,\n",
      "         1.0639e-01, -1.0043e-01,  8.7574e-02,  3.7444e-02,  1.2154e-02,\n",
      "        -1.6456e-02,  2.6893e-02,  7.5731e-02, -1.3113e-03, -7.4825e-02,\n",
      "         5.9883e-02,  8.4668e-02,  3.0258e-02,  2.1865e-02, -4.9336e-02,\n",
      "         1.8141e-02,  1.9344e-02,  7.2990e-02, -1.4085e-02,  9.5024e-02,\n",
      "        -1.1674e-01,  9.6310e-02,  6.2315e-02,  9.4271e-02, -1.0573e-01,\n",
      "         8.0509e-02,  9.8768e-02,  2.7981e-02,  2.3361e-03, -3.2543e-02,\n",
      "         3.1585e-02, -3.8014e-02, -9.9377e-02, -3.3121e-02,  9.0389e-02,\n",
      "         9.8316e-02, -7.5534e-02, -8.2775e-02, -1.0699e-01, -2.4480e-02,\n",
      "        -6.4525e-02,  6.5084e-02,  5.5632e-03,  4.6877e-02,  5.1214e-02,\n",
      "         4.7629e-02,  1.2133e-01, -9.7790e-02, -1.0222e-01, -5.3407e-03,\n",
      "        -1.1943e-01,  4.7111e-02,  3.3431e-02, -1.1441e-02,  9.7181e-02,\n",
      "         1.0804e-01, -6.9525e-02,  4.7147e-02, -7.8196e-02,  1.1318e-02,\n",
      "         1.9316e-03,  9.2746e-03,  1.3018e-02, -6.4106e-02,  5.6049e-02,\n",
      "         8.6196e-02,  1.1275e-01, -1.1591e-01, -1.1756e-01, -1.1774e-01,\n",
      "         4.3403e-02,  1.0928e-02, -1.2107e-01, -6.9024e-02,  8.4988e-02,\n",
      "        -5.1631e-02,  4.2794e-02,  3.8000e-02,  8.6922e-02,  4.5733e-02,\n",
      "         2.2807e-02,  7.7830e-02,  1.0648e-01, -6.0173e-02,  6.7791e-02,\n",
      "        -7.3421e-02, -6.4116e-02,  3.4157e-02, -1.0395e-01,  4.7738e-03,\n",
      "         2.4176e-02, -1.1052e-01, -9.7930e-03,  1.0960e-01],\n",
      "       requires_grad=True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"Nome: {name}\")\n",
    "    print(f\"Shape: {param.shape}\")\n",
    "    print(f\"Valores: {param}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "539ba1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT(\n",
      "  (wte): Embedding(529, 64)\n",
      "  (wpe): Embedding(20, 64)\n",
      "  (qkv_proj): ModuleList(\n",
      "    (0-2): 3 x Linear(in_features=64, out_features=192, bias=True)\n",
      "  )\n",
      "  (out_proj): ModuleList(\n",
      "    (0-2): 3 x Linear(in_features=64, out_features=64, bias=True)\n",
      "  )\n",
      "  (mlp): ModuleList(\n",
      "    (0-2): 3 x Sequential(\n",
      "      (0): Linear(in_features=64, out_features=128, bias=True)\n",
      "      (1): GELU(approximate='tanh')\n",
      "      (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "  (lm_head): Linear(in_features=64, out_features=529, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "344390bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total treinável: 169,169\n"
     ]
    }
   ],
   "source": [
    "total = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total treinável: {total:,d}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49746aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wte.weight                                   33,856\n",
      "wpe.weight                                    1,280\n",
      "qkv_proj.0.weight                            12,288\n",
      "qkv_proj.0.bias                                 192\n",
      "qkv_proj.1.weight                            12,288\n",
      "qkv_proj.1.bias                                 192\n",
      "qkv_proj.2.weight                            12,288\n",
      "qkv_proj.2.bias                                 192\n",
      "out_proj.0.weight                             4,096\n",
      "out_proj.0.bias                                  64\n",
      "out_proj.1.weight                             4,096\n",
      "out_proj.1.bias                                  64\n",
      "out_proj.2.weight                             4,096\n",
      "out_proj.2.bias                                  64\n",
      "mlp.0.0.weight                                8,192\n",
      "mlp.0.0.bias                                    128\n",
      "mlp.0.2.weight                                8,192\n",
      "mlp.0.2.bias                                     64\n",
      "mlp.1.0.weight                                8,192\n",
      "mlp.1.0.bias                                    128\n",
      "mlp.1.2.weight                                8,192\n",
      "mlp.1.2.bias                                     64\n",
      "mlp.2.0.weight                                8,192\n",
      "mlp.2.0.bias                                    128\n",
      "mlp.2.2.weight                                8,192\n",
      "mlp.2.2.bias                                     64\n",
      "lm_head.weight                               33,856\n",
      "lm_head.bias                                    529\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"{name:<40} {param.numel():>10,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45d1f33c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'usar'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_next_token()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5d72df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passo 1: o gato pequeno\n",
      "Passo 2: o gato pequeno projeto\n",
      "Passo 3: o gato pequeno projeto outros\n",
      "Passo 4: o gato pequeno projeto outros oferecer\n",
      "Passo 5: o gato pequeno projeto outros oferecer internet\n",
      "Passo 6: o gato pequeno projeto outros oferecer internet viajar\n",
      "Passo 7: o gato pequeno projeto outros oferecer internet viajar livro\n",
      "Passo 8: o gato pequeno projeto outros oferecer internet viajar livro dentro\n",
      "Passo 9: o gato pequeno projeto outros oferecer internet viajar livro dentro sol\n",
      "Passo 10: o gato pequeno projeto outros oferecer internet viajar livro dentro sol onde\n",
      "Passo 11: o gato pequeno projeto outros oferecer internet viajar livro dentro sol onde rir\n",
      "Passo 12: o gato pequeno projeto outros oferecer internet viajar livro dentro sol onde rir teus\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['o',\n",
       " 'gato',\n",
       " 'pequeno',\n",
       " 'projeto',\n",
       " 'outros',\n",
       " 'oferecer',\n",
       " 'internet',\n",
       " 'viajar',\n",
       " 'livro',\n",
       " 'dentro',\n",
       " 'sol',\n",
       " 'onde',\n",
       " 'rir',\n",
       " 'teus',\n",
       " 'novo']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_all_sentence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50974d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
